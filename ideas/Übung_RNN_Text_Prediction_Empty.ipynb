{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fhac-ewi/recurrent-neural-network/blob/Textprediction/%C3%9Cbung_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYD6gvw1vwii"
   },
   "source": [
    "# Übung RNN\n",
    "\n",
    "## In dieser Übung ...\n",
    "... werden wir ein bisschen lyrisch. Am Ende werden Sie vielleicht noch der nächste Shakespear\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ANQUdX5hyPTu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"Keras Version:\", keras.__version__, \"; Tensorflow version:\", tf.__version__, \"; NumPy version:\", np.__version__, \"Python version:\", \".\".join(str(x) for x in sys.version_info[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WglUJhhgyWSs"
   },
   "source": [
    "## x.1 Erstellen und Vorbereiten eines eigenen Datensatzes \n",
    "\n",
    "Zuerst müssen wir ein paar Daten über die Werke von Shakespear besorgen\n",
    "\n",
    "**Ihre Aufgaben**\n",
    "\n",
    "Führen Sie die folgende Codezelle aus, betrachten Sie den Datensatz und überlegen Sie, was Sie mit den Daten noch tun müssen\n",
    "\n",
    "Hinweis: Müssen Sie die Techte noch etwas bereinigen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir werden der einfach heit halber einzelne Zeichen vorhersagen. Unser vokabular sollte also aus allen Zeichen bestehen, die im text vorkommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def untokenize(tokens):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1CXeYPHyywV"
   },
   "source": [
    "## x.2 One Hot Kodierung\n",
    "\n",
    "Für das Training unseres RNN werden wir eine One Hot kodierung nutzen\n",
    "\n",
    "**Ihre Aufgaben**\n",
    "\n",
    "(1) Implementieren Sie also eine Methode, die für Ihre ausgewählten Tokens eine one hot codierung erzeigt und diese Dann auf den Text anwendet\n",
    "\n",
    "*Himweis:* Eine gute Idee könnte sein eine Klasse zu schreiben, die das vokabular specichert und onehot kodieren und dekodieren kann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "miApcJctvteM"
   },
   "outputs": [],
   "source": [
    "class OneHot(object):\n",
    "    pass\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Für das training brauchen wir nun sequenzen einer bestimmten Länge, das heißt eine Abfolge gegebener Länge von Wörtern\n",
    "\n",
    "Hinweis: Überlegen Sie sich wie lang Sie die Sequenz wählen wollen. Es sollte lang genug sein, dass das Netz zusammen hänge auch über mehrere Sätze lernen kann, aber nicht zu lang, sodass noch genug von den Daten übrig bleibt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_len = # TDOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Nun müssen wir die Daten noch in X und Y aufteilen. Die Y-Werte sind die gleichen, wie die jeweiligen X-Daten, nur um 1 verschoben.\n",
    "\n",
    "*Beispiel:* X: \"Hallo Wel\"; Y: \"allo Welt\"\n",
    "\n",
    "*Hinweis:* Wenn Sie möchten können Sie hier auch schon in trainings und validierungsdaten aufteilen. Diese können während dem training zur Bewertung der Performance genutzt werden, das ist aber nicht nötig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x.3 Erstellen des RNN Modells\n",
    "\n",
    "Hier erstellen wir das eigentliche RNN. Hierfür nutzen wir ein Sequential Model von Keras mit einem RNN und einem Dense Layer mit Softmax zum erstellen der Ausgabe.\n",
    "\n",
    "**Ihre Aufgaben**\n",
    "\n",
    "(1) Erstellen Sie das entsprechende Sequential model. Empfehlung mit adam und categorical_crossentropy. Fügen Sie bei den metrics auch 'accuracy' hinzu. Die werden wir später nutzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = # TODO\n",
    "\n",
    "lstn_input_shape = # TODO\n",
    "\n",
    "rnn_units = 1024 # Kann bei Bedarf angepasst werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axndj50eyWrw"
   },
   "source": [
    "## x.4 Training eines RNN Modells\n",
    "\n",
    "Nun gehts ans trainieren. Nutzen Sie für den Anfang eine kleine Anzahl an epochen um herauszufinden wie viele Sie in einer ertragbaren Zeit machen können. Sollten Sie auf google Colab arbeiten könnte 20 hier ein guter Startwert sein\n",
    "\n",
    "**Ihre Aufgaben**\n",
    "\n",
    "(1) Nutze die Fit methode deines models um es auf den ertellten Trainingsdaten zu trainieren. Wenn Sie validierungsdaten erzeugt haben können Sie diese bei validation_data angeben. Um die Trainingszeit kurz zu halten kann es auch Sinn ergeben hier eine \n",
    "batch_size anzugeben\n",
    "DENKEN SIE DARAN DIE HISTORY ZU SPEICHERN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGpNzqcuyW5-"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Plotten Sie accuracy und loss über die Epochen um bewerten zu können wie gut das Training lief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x.5 Text prediction\n",
    "\n",
    "(1) Schreiben Sie eine Methode, die für einen gegebenen Text das nächste Zeichen prognostiziert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) *Optional:* Nutzen Sie ipywidgets um live vorschläge zurück zu geben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d7pKNy1ycN7"
   },
   "source": [
    "## x.6 *Optional* Vergleich mit LSTM und GRU und ...\n",
    "\n",
    "Trainieren Sie nun modelle mit LSTM und GRU oder anderen Architekturen und vergleichen Sie lernperformance und Ergebnisse. Was fällt Ihnen auf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IehQ7h3uyeY6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x.7 *Noch Optionaler* Ist das Netz jetzt ein Schriftsteller?\n",
    "\n",
    "Was müsste man ändern um nun ein ganzes Buch erstellen zu lassen? Glauben Sie das Ergebniss wäre lesbar?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMq+K20Puo5Sv9kQTS6dlDP",
   "include_colab_link": true,
   "name": "Übung-RNN-Lösung.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
