{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ãœbung-RNN-LÃ¶sung.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fhac-ewi/recurrent-neural-network/blob/main/%C3%9Cbung_RNN_L%C3%B6sung.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYD6gvw1vwii"
      },
      "source": [
        "# Ãœbung 7 - Rekurrente neuronale Netze (RNNs)\n",
        "\n",
        "## In dieser Ãœbung ...\n",
        "... beschÃ¤ftigen wir uns mit rekurrenten neuronalen Netzen, die unter anderem fÃ¼r die Textvorhersage (`text prediction`) eingesetzt werden kÃ¶nnen. Sie werden ein eigenes Modell zur Vorhersage weiterer Buchstaben (Zeichen) zu einer gegebenen Buchstabensequenz erstellen.\n",
        "\n",
        "Dazu werden Sie die drei aus der Vorlesung bekannten Varianten von RNNs (Standard, LSTM und GRU) mit Keras implementieren und die Genauigkeit (Accuracy) der Netze miteinander vergleichen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a_ZEFJfHuuF"
      },
      "source": [
        "## 7.0 Vorbereitung\n",
        "\n",
        "In diesem Abschnitt mÃ¼ssen Sie nichts programmieren! ðŸŽ‰\n",
        "\n",
        "Wir haben bereits alle notwendigen Imports fÃ¼r diese Ãœbung hinzugefÃ¼gt, sodass Sie direkt starten kÃ¶nnen. Sie mÃ¼ssen lediglich die GPU UnterstÃ¼tzung in Google Colab aktivieren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc_GxdsyIDYP"
      },
      "source": [
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Aktivieren Sie bitte die GPU UnterstÃ¼tzung in Google Colab. Wechseln Sie unter dem Reiter `Laufzeit` -> `Laufzeittyp Ã¤ndern` von `None` auf `GPU` und bestÃ¤tigen Sie diese Ã„nderung.\n",
        "\n",
        "(2) FÃ¼hren Sie den folgenden Codezelle aus, um die erforderlichen Bibliotheken zu importieren und die GPU UnterstÃ¼tzung zu prÃ¼fen. \n",
        "\n",
        "  * Hinweis: Wenn Sie dieses Notebook mit dem Direktlink von GitHub geÃ¶ffnet haben, wird bei der erstmaligen AusfÃ¼hrung eine Warnung angezeigt. Diese mÃ¼ssen Sie durch den Klick auf `Trotzdem ausfÃ¼hren` bestÃ¤tigen. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-cFD9IFItkB",
        "outputId": "57de87f7-1e81-4e3c-ff43-1cbf7a8b1d64"
      },
      "source": [
        "# Import everything needed for this exercise \n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime, timedelta\n",
        "from termcolor import colored\n",
        "\n",
        "print(f\"Keras Version: {keras.__version__}; Tensorflow version: {tf.__version__}; NumPy version: {np.__version__}; Python version: \", \".\".join(str(x) for x in sys.version_info[:3]))\n",
        "\n",
        "# Reset random number generators\n",
        "seed = 1337\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Check GPU support\n",
        "from tensorflow.python.client import device_lib\n",
        "physical_devices = device_lib.list_local_devices()\n",
        "print(\"You are using\", len(physical_devices), \"local devises.\", len([x for x in physical_devices if x.device_type == \"GPU\"]), \"are GPUs\")\n",
        "for i, d in enumerate(physical_devices):\n",
        "    print(\"  ->Device\", i+1, \"is a\", d.device_type, \"=>\", d.physical_device_desc if len(d.physical_device_desc) > 0 else d.name)\n",
        "\n",
        "if len([x for x in physical_devices if x.device_type == \"GPU\"]) == 0:\n",
        "  raise Exception(\"Please enable GPU support before using this notebook. See here: [Runtime] -> [Change runtime type]\")    \n",
        "\n",
        "print(\"\\nðŸŽ‰ðŸŽ‰ðŸŽ‰ You are ready to go! ðŸŽ‰ðŸŽ‰ðŸŽ‰\")  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keras Version: 2.4.3; Tensorflow version: 2.4.1; NumPy version: 1.19.5; Python version:  3.7.10\n",
            "You are using 2 local devises. 1 are GPUs\n",
            "  ->Device 1 is a CPU => /device:CPU:0\n",
            "  ->Device 2 is a GPU => device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "\n",
            "ðŸŽ‰ðŸŽ‰ðŸŽ‰ You are ready to go! ðŸŽ‰ðŸŽ‰ðŸŽ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1CXeYPHyywV"
      },
      "source": [
        "## 7.1 One Hot Kodierung\n",
        "\n",
        "Wir haben in der Vorlesung die One Hot Kodierung (1-aus-n-Code) kennen gelernt. Diese ermÃ¶glicht es Zeichen eines Alphabets als Vektoren darzustellen. \n",
        "\n",
        "FÃ¼r ein Alphabet mit `n` einzigartigen Zeichen wird ein Vektor der LÃ¤nge `n` benÃ¶tigt. Jedes einzigartige Zeichen wird hierbei als Einheitsvektor definiert. Eine Zeichensequenz mit `m` Zeichen werden als `m` Vektoren mit jeweils der LÃ¤nge `n` dargestellt.  \n",
        "\n",
        "**Hinweis** Die vorliegende Implementierung ist fÃ¼r den Umgang mit Zeichen auÃŸerhalb des Alphabets konzipiert. Deshalb wird zur Darstellung eines Alphabets mit `n` einzigartigen Zeichen ein Vektor der LÃ¤nge `n+1` erstellt. Alle Zeichen auÃŸerhalb des Alphabets werden durch das `unknown_token` ersetzt. \n",
        "\n",
        "FÃ¼r das Training unseres Netzes werden wir die One Hot Kodierung zur Umwandlung eines Textes in Trainingsdaten nutzen. (Aufgabe 7.2)\n",
        "\n",
        "* Hinweis: FÃ¼r weitere Informationen zur One Hot Kodierun schlagen Sie diese in der Vorlesung nach oder benutzen Sie das [Internet](https://de.wikipedia.org/wiki/1-aus-n-Code)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miApcJctvteM"
      },
      "source": [
        "class OneHot(object):\n",
        "    def __init__(self, tokens, unknown_token = \"[UNKNOWN]\"):\n",
        "        '''\n",
        "        tokens: The tokens you want to be able to encode and decode\n",
        "        unknown_token: The token to be used when decoding and the net wants to use a not known char\n",
        "        '''\n",
        "        self.tokens = tokens\n",
        "        self.unknown_token = unknown_token\n",
        "        # Store a bidirectional dictionary containing the characters\n",
        "        self.char_to_index = dict((token, i + 1) for i, token in enumerate(self.tokens))\n",
        "        self.index_to_char = dict((i + 1, token) for i, token in enumerate(self.tokens))\n",
        "        pass\n",
        "\n",
        "    def encode(self, text_as_tokens, dtype=np.bool_):\n",
        "        '''\n",
        "        text_as_tokens: List of tokens\n",
        "        '''\n",
        "        # Create the encoding matrix\n",
        "        enc = np.empty((len(text_as_tokens), len(self.tokens) + 1), dtype=dtype)\n",
        "        for i, token in enumerate(text_as_tokens):\n",
        "            # Encode every char\n",
        "            enc[i] = self.encode_token(token=token, l=len(self.tokens) + 1, dtype=dtype)\n",
        "        return enc\n",
        "    \n",
        "    def encode_token(self, token, l, dtype=np.bool_):\n",
        "        '''\n",
        "        token: Single token\n",
        "        l: length of array to be returned. At position zero it is stored if the char is unknown\n",
        "        '''\n",
        "        ret = np.zeros((1, l), dtype=dtype)\n",
        "        if token not in self.char_to_index:\n",
        "            ret[0, 0] = 1\n",
        "        else:\n",
        "            ret[0, self.char_to_index[token]] = 1\n",
        "        return ret\n",
        "    \n",
        "    def decode(self, mat, unknown_token=None):         \n",
        "        '''\n",
        "        mat: matrix to be decoded. Has to be of shape (len_of_text, vocab_size)\n",
        "        unknown_token: Unknown token. If none uses the one from __init__\n",
        "        '''\n",
        "        return [self.decode_token(mat[x]) for x in range(mat.shape[0])]\n",
        "    \n",
        "    def decode_token(self, vec, unknown_token=None):\n",
        "        '''\n",
        "        vec: Vector that should be decoded. Has to be on vocab length\n",
        "        unknown_token: Unknown token. If none uses the one from __init__\n",
        "        '''\n",
        "        if unknown_token is None:\n",
        "            unknown_token = self.unknown_token\n",
        "        if isinstance(vec, tf.Tensor):\n",
        "            vec = vec.numpy()\n",
        "        if isinstance(vec, np.ndarray):\n",
        "            # Use argmax since this will be used in the model created later\n",
        "            am = np.argmax(vec)\n",
        "        else:\n",
        "            am = vec\n",
        "        if am == 0:\n",
        "            return unknown_token\n",
        "        return self.index_to_char[am]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9nyVSBS_RnK"
      },
      "source": [
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Untersuchen Sie gegebene Klasse zur One Hot Kodierung und die Funktion der einzelnen Methoden. \n",
        "\n",
        "(2) Erstellen Sie fÃ¼r das folgendes Alphabet `HWedlor` eine Instanz der Klasse `OneHot`. \n",
        "\n",
        "(3) Kodieren Sie nun die Zeichenfolge `Hello World!` mit der One Hot Kodierung. Wie wird das Zeichen `H` dargestellt? Geben Sie die Dimensionen des Vektors an.\n",
        "\n",
        "* Hinweis: Sie kÃ¶nnen zur Umwandlung des Strings in eine Liste von Zeichen die Funktion `tokenize` verwenden. Dies ist aber nicht zwingend erforderlich, da Python den String automatisch als Liste interpretieren kann."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXopuHLJadWN"
      },
      "source": [
        "> <Antwort hier einfÃ¼gen>\n",
        "\n",
        "> **MusterlÃ¶sung:** Das Zeichen `H` wird als Vektor `[False  True False False False False False False]` \n",
        "dargestellt. Die Dimension ist `1x8`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jCputAba8UN"
      },
      "source": [
        "(4) Wandeln Sie die kodierte Zeichenfolge zurÃ¼ck in einen fÃ¼r Menschen lesbaren Text. Entspricht der zurÃ¼ckgewandelte Text dem ursprÃ¼nglichen Input? Falls nicht, beschreiben Sie die Ursache.\n",
        "\n",
        "* Hinweis: FÃ¼r eine schÃ¶nere Ausgabe kann der enkodierte Text mit der Funktion `untokenize` in einen String gewandelt werden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPiAwayxbi16"
      },
      "source": [
        "> <Antwort hier einfÃ¼gen>\n",
        "\n",
        "> **MusterlÃ¶sung:** Der ursprÃ¼ngliche Text und der kodierte und dekodierte Text ist nicht mehr identisch, da zwei Zeichen (Leerzeichen, Ausrufezeichen) nicht im Alphabet vorhanden sind. Durch HinzufÃ¼gen dieser Zeichen ins Alphabet wÃ¼rde man den ursprÃ¼nglichen Text erhalten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjFH6Rbeab4P",
        "outputId": "ade81b82-06ee-4a46-fad4-5ba076a31df5"
      },
      "source": [
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    Converts the given text (string) in a list of chars.\n",
        "    \"\"\"\n",
        "    return list(text)\n",
        "\n",
        "def untokenize(tokens):\n",
        "    \"\"\"\n",
        "    Converts the given tokens (list of chars) in a string.\n",
        "    \"\"\"\n",
        "    return \"\".join(tokens)\n",
        "\n",
        "tokens = 'HWedlor'\n",
        "\n",
        "# code here\n",
        "one_hot = OneHot(tokens=tokens)\n",
        "\n",
        "text='Hello World!'\n",
        "\n",
        "coded_text = one_hot.encode(text)\n",
        "print(\"Shape of coded text: \", coded_text.shape)\n",
        "print(\"H coded (first letter in coded text): \", coded_text[0])\n",
        "\n",
        "encoded_text = one_hot.decode(coded_text)\n",
        "\n",
        "print(untokenize(encoded_text))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of coded text:  (12, 8)\n",
            "H coded (first letter in coded text):  [False  True False False False False False False]\n",
            "Hello[UNKNOWN]World[UNKNOWN]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WglUJhhgyWSs"
      },
      "source": [
        "## 7.2 Datensatz vorbereiten\n",
        "\n",
        "In dieser Ãœbung verwenden wir das Buch Shakespeare TODO als Datensatz zum Training und Test unserer Modelle. Ziel der Modelle ist die Vorhersage weiterer Zeichen zu einer gegebenen Zeichensequenz.\n",
        "\n",
        "In diesem Aufgabenteil werden die Daten eingelesen, mithilfe der One Hot Kodierung umgewandelt und anschlieÃŸend in Trainingsdaten und Validierungsdaten aufgeteilt.\n",
        "\n",
        "* Hinweis: Sie kÃ¶nnen theoretisch jeden beliebigen Text als Datensatz fÃ¼r das Training des Modells verwenden. (z.B. Harry Potter BÃ¼cher, Coronaschutzverordnungen, Nachrichtenartikel, ...)\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) FÃ¼hren Sie die folgende Codezelle aus, um das Buch Shakespeare TODO einzulesen. Untersuchen Sie den Datensatz, indem Sie einen kurzen Auszug des Textes ausgeben.\n",
        "\n",
        "(2) Erstellen Sie aus dem Text das Alphabet (`tokens`) und geben die LÃ¤nge aus. Das Alphabet soll alle Zeichen des Textes enthalten.\n",
        "\n",
        "* Hinweis: Sie kÃ¶nnen den `text` mit der Funktion `tokenize` in eine Liste umwandeln. Dieser kann dann zu einem [Set](https://docs.python.org/3/tutorial/datastructures.html#sets) gewandelt werden.\n",
        "\n",
        "(3) Erstellen Sie fÃ¼r das Alphabet eine One Hot Kodierung und wenden diese auf den `text` an. Nutzen Sie dazu Ihre die Erkentnisse aus Aufgabe 7.1.\n",
        "\n",
        "(4) Teilen Sie den kodierten Text in Sequenzen auf. Wie wÃ¼rden Sie die LÃ¤nge der einzelnen Sequenzen wÃ¤hlen? \n",
        "Verwenden Sie dazu die Funktion vorgegebene Funktion `sequenze_split`.\n",
        "\n",
        "* ErklÃ¤rung: Wieso wird der Text in Sequenzen gesplittet?\n",
        "</br>TODO Wieso machen wir das?\n",
        "\n",
        "* Hinweis: Die Sequenzen sollten lang genug sein, dass das RNN ZusammenhÃ¤nge in einem Satz (und ggf. darÃ¼ber hinaus) erlenen kann. Die SequenzlÃ¤nge sollte kurz genug sein, damit eine ausreichende Anzahl fÃ¼r das Training vorhanden ist.\n",
        "\n",
        "TODO RIOT Hinweis mit unserer SequenzlÃ¤nge.\n",
        "\n",
        "(5) Erstellen Sie nun aus den sequenzierten Daten das Feature `X` und das Label `y`. FÃ¼r die Vorhersage von einzelnen Zeichen ist jeweils das nÃ¤chste Zeichen das Label des vorherigen Zeichens. Das Label `y` wird deshalb aus den gleichen Werte des Features `X` gebildet, ist jedoch um +1 verschoben. \n",
        "\n",
        "\n",
        "* Beispiel: Die Sequenz `Hello World!` kann in **X** `Hello World` mit dem zugehÃ¶rigen Label **y** `ello World!` aufgeteilt werden.\n",
        "* Hinweis: Untersuchen Sie die RÃ¼ckgabe der Funktion `sequenze_split`. In welcher der drei Komponenten mÃ¼ssen Sie die Verschiebung vornehmen.\n",
        "\n",
        "(6) Konvertieren Sie nun die Daten in ein Trainings- und Validierungsset. Nutzen Sie dafÃ¼r die Funktion `train_test_split` (Eine Dokumentation finden Sie [hier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN0KsVCb_Rm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd610da-2465-43a5-fa88-14d4be040394"
      },
      "source": [
        "# maximum text length \n",
        "# 1. Protection against \"OutOfMemory\" (poor RAM ðŸ˜¥)\n",
        "# 2. Adjustment for making training faster (but you will gain less accuracy)\n",
        "MAX_TEXT_LEN = 700_000 \n",
        "\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "# TODO path_to_file = tf.keras.utils.get_file('german_news.txt', 'https://raw.githubusercontent.com/tblock/10kGNAD/master/articles.csv') # Taken from https://github.com/tblock/10kGNAD\n",
        "\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print(f'Length of text: {len(text)} characters')\n",
        "if len(text) > MAX_TEXT_LEN:\n",
        "    print(\"Text is too long. Cutting it to\", MAX_TEXT_LEN, f\"characters. That is {100 * MAX_TEXT_LEN / len(text):6.2f} %\")\n",
        "    text = text[:MAX_TEXT_LEN]\n",
        "\n",
        "# helper function for 7.2.4\n",
        "def sequenze_split(coded_text, sequence_len):\n",
        "    \"\"\"\n",
        "    Splits a given coded text (text converted with OneHot) into multiple subsequenzes\n",
        "    \"\"\"\n",
        "    target_shape = (int(coded_text.shape[0] / (sequence_len + 1)) , (sequence_len + 1) , coded_text.shape[1])\n",
        "    coded_text_seq = np.empty(target_shape, dtype=coded_text.dtype)\n",
        "    for s in range(coded_text_seq.shape[0]):\n",
        "        coded_text_seq[s] = coded_text[s * (sequence_len + 1):(s + 1) * (sequence_len + 1)]\n",
        "\n",
        "    # returns 3D matrix (sequences, letters per sequence, letter as one hot coded vector)    \n",
        "    return coded_text_seq    \n",
        "\n",
        "# code here   \n",
        "# Aufgabe 7.2.1 \n",
        "print(\"Segment of text:\")\n",
        "print(\"-\" * 60)\n",
        "print(colored(text[:250], 'blue')) \n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Aufgabe 7.2.2 - Alphabet erstellen\n",
        "tokens = sorted(set(text))\n",
        "print(\"Length of raw text:\", len(text))\n",
        "print(\"Numbers of tokens (unique letters): \", len(tokens))\n",
        "\n",
        "\n",
        "# Aufgabe 7.2.3 - One Hot\n",
        "one_hot = OneHot(tokens=tokens)\n",
        "coded_text = one_hot.encode(text)\n",
        "print(\"Shape of coded text: \", coded_text.shape)\n",
        "\n",
        "# Aufgabe 7.2.4 - Aufteilung in Sequenzen\n",
        "sequence_len = 150\n",
        "coded_text_seq = sequenze_split(coded_text, sequence_len)\n",
        "print(\"Shape of coded text split into sequences\", coded_text_seq.shape)\n",
        "\n",
        "# Aufgabe 7.2.5\n",
        "X = coded_text_seq[:, :-1]\n",
        "y = coded_text_seq[:, 1:]\n",
        "\n",
        "# Aufgabe 7.2.6\n",
        "validation_size = 1/4\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=validation_size)\n",
        "\n",
        "print(\"X_train:\", X_train.shape, X_train.dtype)\n",
        "print(\"y_train:\", y_train.shape, y_train.dtype)\n",
        "print(\"X_val  :\", X_val.shape, X_val.dtype)\n",
        "print(\"y_val  :\", y_val.shape, y_val.dtype)\n",
        "\n",
        "print(\"-\" * 40)\n",
        "print(colored(untokenize(one_hot.decode(X_train[0])), 'blue'))\n",
        "print(\"-\" * 40)\n",
        "print(colored(untokenize(one_hot.decode(y_train[0])), 'green'))\n",
        "print(\"-\" * 40)    "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n",
            "Text is too long. Cutting it to 700000 characters. That is  62.76 %\n",
            "Segment of text:\n",
            "------------------------------------------------------------\n",
            "\u001b[34mFirst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\u001b[0m\n",
            "------------------------------------------------------------\n",
            "Length of raw text: 700000\n",
            "Numbers of tokens (unique letters):  65\n",
            "Shape of coded text:  (700000, 66)\n",
            "Shape of coded text split into sequences (6930, 101, 66)\n",
            "X_train: (5197, 100, 66) bool\n",
            "y_train: (5197, 100, 66) bool\n",
            "X_val  : (1733, 100, 66) bool\n",
            "y_val  : (1733, 100, 66) bool\n",
            "----------------------------------------\n",
            "\u001b[34m spend another such a night,\n",
            "Though 'twere to buy a world of happy days,\n",
            "So full of dismal terror wa\u001b[0m\n",
            "----------------------------------------\n",
            "\u001b[32mspend another such a night,\n",
            "Though 'twere to buy a world of happy days,\n",
            "So full of dismal terror was\u001b[0m\n",
            "----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDvkDpWsysjl"
      },
      "source": [
        "ðŸŽ‰ðŸŽ‰ðŸŽ‰ **Geschafft!** ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
        "\n",
        "Sie haben nun aus einem Buch Trainingsdaten fÃ¼r ein RNN zur Vorhersage von Zeichen erstellt! \n",
        "- Text einlesen\n",
        "- Text in Tokens umwandeln\n",
        "- Alphabet festlegen\n",
        "- One Hot Kodierung erstellen und anwenden\n",
        "- In Sequenzen aufteilen\n",
        "- `X` und `y` festlegen\n",
        "- Aufteilung in Training und Validierungsset\n",
        "\n",
        "... jetzt kÃ¶nnen Sie mit dem eigentlichen Modell fortfahren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOMFCH7V_RnM"
      },
      "source": [
        "## 7.3 RNN Modell erstellen\n",
        "\n",
        "In dieser Ãœbung wird nun das rekurrente neuronale Netz zur Vorhersage von Buchstaben zu einer gegebenen Sequenz erstellt. Das Training wird in der nÃ¤chsten Aufgabenteil durchgefÃ¼hrt.\n",
        "\n",
        "In diesem Aufgabenteil wird ein Simple RNN (auch Vanilla bezeichnet) trainiert.\n",
        "\n",
        "Sie verwenden dazu ein *SimpleRNN* (Link) \n",
        "\n",
        "Hier erstellen wir das eigentliche RNN. HierfÃ¼r nutzen wir ein Sequential Model von Keras mit einem RNN und einem Dense Layer mit Softmax zum erstellen der Ausgabe.\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Bestimmen Sie nun die Parameter, die fÃ¼r das Modell benÃ¶tigt werden.\n",
        "- Shape der Eingabe/des Trainingdatensatzes. (Anzahl Zeichen, LÃ¤nge eines vektorisierten Zeichens)\n",
        "- LÃ¤nge des Alphabets (inklusive des `unknown_tokens`). Also die Anzahl der Tokens, die das Modell vorhersagen kÃ¶nnen soll.\n",
        "  \n",
        "\n",
        "(2) Erstellen Sie das entsprechende [Sequential](https://keras.io/api/models/sequential/) Modell und fÃ¼gen folgende Schichten hinzu:\n",
        "- [SimpleRNN](https://keras.io/api/layers/recurrent_layers/simple_rnn/) mit 1024 Units als Output Space (= GrÃ¶ÃŸe des Hidden State), dem Parameter `return_sequences=true` und der Shape der Eingabe. \n",
        "- [Dense](https://keras.io/api/layers/core_layers/dense/) mit der Anzahl der Tokens und der Aktivierungsfunktion `softmax`.\n",
        "\n",
        "Kompilieren Sie anschlieÃŸend das Modell mit der `categorical_crossentropy` Loss Function, dem `Adam` Optimizer und fÃ¼gen als Metrics die `accuracy` hinzu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Uh7RmR_RnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d549a89-24b0-4ab1-8950-62a125e0f832"
      },
      "source": [
        "# code here\n",
        "# Aufgabe 7.3.1\n",
        "# Length of the vocabulary in chars\n",
        "vocab_size = X_train.shape[-1]\n",
        "print(\"Numbers of unique tokens: \", vocab_size)\n",
        "\n",
        "# The input shape\n",
        "input_shape = X_train.shape[1:]\n",
        "print(\"Input shape: \", input_shape)\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 2048\n",
        "\n",
        "# Aufgabe 7.3.2 - SimpleRNN\n",
        "model = tf.keras.Sequential(name=\"SimpleRNN_Model\")\n",
        "model.add(tf.keras.layers.SimpleRNN(rnn_units, return_sequences=True, input_shape=input_shape, name=\"The_Brain\"))\n",
        "model.add(tf.keras.layers.Dense(vocab_size, activation='softmax', name=\"The_Hand\"))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Zusatz\n",
        "input_example_batch = X_train[0]\n",
        "input_example_batch = input_example_batch.reshape((1, *input_example_batch.shape))\n",
        "\n",
        "example_batch_predictions = model.predict(input_example_batch)\n",
        "print(input_example_batch.shape, y_train[0].shape, example_batch_predictions.shape)\n",
        "\n",
        "print(\"Test sequence:\", \"\\n\", \"-\" * 40, \"\\n\", colored(untokenize(one_hot.decode(X_train[0])), 'blue'), \"\\n\", \"-\"*40)\n",
        "print(\"Expected result:\", \"\\n\", \"-\" * 40, \"\\n\", colored(untokenize(one_hot.decode(y_train[0])), 'green'), \"\\n\", \"-\"*40)\n",
        "print(\"Untrained prediction:\", \"\\n\", \"-\" * 40, \"\\n\", colored(untokenize(one_hot.decode(example_batch_predictions[0])), 'red'), \"\\n\", \"-\"*40)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numbers of unique tokens:  66\n",
            "Input shape:  (100, 66)\n",
            "Model: \"SimpleRNN_Model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "The_Brain (SimpleRNN)        (None, 100, 2048)         4331520   \n",
            "_________________________________________________________________\n",
            "The_Hand (Dense)             (None, 100, 66)           135234    \n",
            "=================================================================\n",
            "Total params: 4,466,754\n",
            "Trainable params: 4,466,754\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(1, 100, 66) (100, 66) (1, 100, 66)\n",
            "Test sequence: \n",
            " ---------------------------------------- \n",
            " \u001b[34m spend another such a night,\n",
            "Though 'twere to buy a world of happy days,\n",
            "So full of dismal terror wa\u001b[0m \n",
            " ----------------------------------------\n",
            "Expected result: \n",
            " ---------------------------------------- \n",
            " \u001b[32mspend another such a night,\n",
            "Though 'twere to buy a world of happy days,\n",
            "So full of dismal terror was\u001b[0m \n",
            " ----------------------------------------\n",
            "Untrained prediction: \n",
            " ---------------------------------------- \n",
            " \u001b[31mXWzma$XtC$;Bx\n",
            "dHwrbVyxC &IM,jtUB!f$WXhpCM?KBHLUL,OXTyHFbRq3m[UNKNOWN]bVjecx[UNKNOWN]?qOeIvUMMSYv L[UNKNOWN]rqqGmmA!Nb,IXwEiU\u001b[0m \n",
            " ----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axndj50eyWrw"
      },
      "source": [
        "## 7.4 RNN Modell trainieren\n",
        "\n",
        "\n",
        "TODO \n",
        "Nun gehts ans trainieren. Nutzen Sie fÃ¼r den Anfang eine kleine Anzahl an epochen um herauszufinden wie viele Sie in einer ertragbaren Zeit machen kÃ¶nnen. Sollten Sie auf google Colab arbeiten kÃ¶nnte 20 hier ein guter Startwert sein\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Nutze die Fit methode deines models um es auf den ertellten Trainingsdaten zu trainieren. Wenn Sie validierungsdaten erzeugt haben kÃ¶nnen Sie diese bei validation_data angeben. Um die Trainingszeit kurz zu halten kann es auch Sinn ergeben hier eine batch_size anzugeben\n",
        "\n",
        "* Hinweis: Eine val_accuracy von circa 40% nach 10 Epochen oder von 50% nach 20 Epochen ist fÃ¼r dieses Modell natÃ¼rlich noch lange nicht gut, aber ganz passabel. Erwarten Sie bitte nicht zu viel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_SVsygGOYVa"
      },
      "source": [
        "EPOCHS = 20\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGpNzqcuyW5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "771d16c5-86c6-4c0b-b550-c4e0450bd113"
      },
      "source": [
        "t1 = time.time()\n",
        "hist = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=EPOCHS,\n",
        "                  validation_data=(X_val, y_val))\n",
        "t2 = time.time()\n",
        "\n",
        "print(\"Training took: \", timedelta(seconds=t2-t1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "163/163 [==============================] - 16s 95ms/step - loss: 3.6712 - accuracy: 0.1335 - val_loss: 3.2370 - val_accuracy: 0.1543\n",
            "Epoch 2/20\n",
            "163/163 [==============================] - 15s 90ms/step - loss: 3.1607 - accuracy: 0.1832 - val_loss: 2.8161 - val_accuracy: 0.2740\n",
            "Epoch 3/20\n",
            "163/163 [==============================] - 15s 91ms/step - loss: 2.9168 - accuracy: 0.2416 - val_loss: 2.7301 - val_accuracy: 0.2609\n",
            "Epoch 4/20\n",
            "163/163 [==============================] - 15s 91ms/step - loss: 2.7170 - accuracy: 0.2675 - val_loss: 2.5407 - val_accuracy: 0.2996\n",
            "Epoch 5/20\n",
            "163/163 [==============================] - 15s 92ms/step - loss: 2.5412 - accuracy: 0.2997 - val_loss: 2.5030 - val_accuracy: 0.3133\n",
            "Epoch 6/20\n",
            "163/163 [==============================] - 15s 91ms/step - loss: 2.4368 - accuracy: 0.3204 - val_loss: 2.3879 - val_accuracy: 0.3279\n",
            "Epoch 7/20\n",
            "163/163 [==============================] - 15s 90ms/step - loss: 2.4484 - accuracy: 0.3210 - val_loss: 2.3650 - val_accuracy: 0.3319\n",
            "Epoch 8/20\n",
            "163/163 [==============================] - 15s 91ms/step - loss: 2.3505 - accuracy: 0.3399 - val_loss: 2.3292 - val_accuracy: 0.3365\n",
            "Epoch 9/20\n",
            "163/163 [==============================] - 15s 90ms/step - loss: 2.2924 - accuracy: 0.3518 - val_loss: 2.2838 - val_accuracy: 0.3565\n",
            "Epoch 10/20\n",
            "163/163 [==============================] - 15s 92ms/step - loss: 2.2602 - accuracy: 0.3615 - val_loss: 2.2903 - val_accuracy: 0.3406\n",
            "Epoch 11/20\n",
            "163/163 [==============================] - ETA: 0s - loss: 2.2338 - accuracy: 0.3650"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwFD7439_RnO"
      },
      "source": [
        "(2) Plotten Sie accuracy und loss Ã¼ber die Epochen um bewerten zu kÃ¶nnen wie gut das Training lief"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCn3o8K9_RnO"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1)\n",
        "\n",
        "ax.plot(hist.history[\"loss\"], label='loss')\n",
        "ax.plot(hist.history[\"accuracy\"], label='accuracy')\n",
        "ax.plot(hist.history[\"val_loss\"], label='validation loss')\n",
        "ax.plot(hist.history[\"val_accuracy\"], label='validation accuracy')\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "ax.legend()\n",
        "\n",
        "fig.set_size_inches(20, 10)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhQ4HP55Fidk"
      },
      "source": [
        "# Zusatz\n",
        "input_example_batch = X_train[0]\n",
        "input_example_batch = input_example_batch.reshape((1, *input_example_batch.shape))\n",
        "\n",
        "example_batch_predictions = model.predict(input_example_batch)\n",
        "print(input_example_batch.shape, y_train[0].shape, example_batch_predictions.shape)\n",
        "\n",
        "print(\"Test sequence:\", \"\\n\", \"-\" * 40, \"\\n\", colored(untokenize(one_hot.decode(X_train[0])), 'blue'), \"\\n\", \"-\"*40)\n",
        "print(\"Expected result:\", \"\\n\", \"-\" * 40, \"\\n\", colored(untokenize(one_hot.decode(y_train[0])), 'green'), \"\\n\", \"-\"*40)\n",
        "print(\"Trained prediction:\", \"\\n\", \"-\" * 40, \"\\n\", colored(untokenize(one_hot.decode(example_batch_predictions[0])), 'red'), \"\\n\", \"-\"*40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sslY_jvfwHN-"
      },
      "source": [
        "TODO Was hat er gelernt?\n",
        "\n",
        "- GroÃŸschreibung nach Punkte\n",
        "- WÃ¶rter\n",
        "- ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxNyKthd_RnP"
      },
      "source": [
        "## x.5 Text prediction\n",
        "\n",
        "(1) Schreiben Sie eine Methode, die fÃ¼r einen gegebenen Text das nÃ¤chste Zeichen prognostiziert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3wVdygn_RnQ"
      },
      "source": [
        "def predict(txt, one_hot, trainied_model):\n",
        "    encoded_txt = one_hot.encode(tokenize(txt))\n",
        "    prediction = trainied_model.predict(encoded_txt.reshape((1, *encoded_txt.shape)))\n",
        "    return untokenize(one_hot.decode(prediction[0]))[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67T8xcMS_RnQ"
      },
      "source": [
        "(2) *Optional:* Nutzen Sie ipywidgets um live vorschlÃ¤ge zurÃ¼ck zu geben"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApEZl0IK_RnQ"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ENo5TOT_RnR"
      },
      "source": [
        "def verbose_prediction(txt, one_hot, trainied_model):\n",
        "    if len(txt) == 0:\n",
        "        txt = \" \"\n",
        "    prediction = predict(txt=txt, one_hot=one_hot, trainied_model=trainied_model)\n",
        "    print(f\"I think the next will be \\\"{prediction}\\\" after you said \\\"{txt}\\\"\")\n",
        "\n",
        "w = widgets.interactive(verbose_prediction,\n",
        "                        txt=widgets.Text(value='Hello Worl', placeholder='Type something', description='Your text:', disabled=False),\n",
        "                        one_hot=widgets.fixed(one_hot),\n",
        "                        trainied_model=widgets.fixed(model),\n",
        "                       )\n",
        "\n",
        "verbose_prediction(\"Spor\", one_hot=one_hot, trainied_model=model)\n",
        "verbose_prediction(\"FuÃŸba\", one_hot=one_hot, trainied_model=model)\n",
        "\n",
        "display(w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d7pKNy1ycN7"
      },
      "source": [
        "## x.6 *Optional* Vergleich mit LSTM und GRU und ...\n",
        "\n",
        "Trainieren Sie nun modelle mit LSTM und GRU oder anderen Architekturen und vergleichen Sie lernperformance und Ergebnisse. Was fÃ¤llt Ihnen auf?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IehQ7h3uyeY6"
      },
      "source": [
        "model_lstm = tf.keras.Sequential(name=\"LSTM_Model\")\n",
        "model_lstm.add(tf.keras.layers.LSTM(rnn_units, return_sequences=True, input_shape=input_shape, name=\"The_Brain\"))\n",
        "model_lstm.add(tf.keras.layers.Dense(vocab_size, activation='softmax', name=\"The_Hand\"))\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_lstm.summary()\n",
        "\n",
        "model_gru = tf.keras.Sequential(name=\"GRU_Model\")\n",
        "model_gru.add(tf.keras.layers.LSTM(rnn_units, return_sequences=True, input_shape=input_shape, name=\"The_Brain\"))\n",
        "model_gru.add(tf.keras.layers.Dense(vocab_size, activation='softmax', name=\"The_Hand\"))\n",
        "model_gru.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_gru.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knXfKSKy_RnS"
      },
      "source": [
        "t1 = time.time()\n",
        "hist_lstm = model_lstm.fit(X_train, y_train,\n",
        "                           batch_size=BATCH_SIZE,\n",
        "                           epochs=EPOCHS,\n",
        "                           validation_data=(X_val, y_val))\n",
        "t2 = time.time()\n",
        "t_lstm = t2 - t1\n",
        "\n",
        "t1 = time.time()\n",
        "hist_gru = model_gru.fit(X_train, y_train,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         epochs=EPOCHS,\n",
        "                         validation_data=(X_val, y_val))\n",
        "t2 = time.time()\n",
        "t_gru = t2 - t1\n",
        "\n",
        "print(\"LSTM Training took:\", timedelta(seconds=t_lstm))\n",
        "print(\"GRU  Training took:\", timedelta(seconds=t_gru))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HlKt70B_RnT"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1)\n",
        "\n",
        "for n, h in [(\"simple rnn\", hist), (\"lstm\", hist_lstm), (\"gru\", hist_gru)]:\n",
        "\n",
        "    ax.plot(h.history[\"loss\"], label=f'{n} loss')\n",
        "    ax.plot(h.history[\"accuracy\"], label=f'{n} accuracy')\n",
        "    ax.plot(h.history[\"val_loss\"], label=f'{n} validation loss')\n",
        "    ax.plot(h.history[\"val_accuracy\"], label=f'{n} validation accuracy')\n",
        "\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "ax.legend()\n",
        "\n",
        "fig.set_size_inches(20, 10)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMWgGgRZ_RnT"
      },
      "source": [
        "## x.7 *Noch Optionaler* Ist das Netz jetzt ein Schriftsteller?\n",
        "\n",
        "Was mÃ¼sste man Ã¤ndern um nun ein ganzes Buch erstellen zu lassen? Glauben Sie das Ergebniss wÃ¤re lesbar?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wyhz--mz_RnT"
      },
      "source": [
        "HierfÃ¼r wollen wir wenn mÃ¶glich beliebig viele Zeichen generieren, dabei den hidden state behalten und nicht konstant das bisher geschriebene als Input wieder einfÃ¼gen. Deshalb nutzen wir hier eine eigene Klasse fÃ¼r das Netz, die dann die Layer enthÃ¤lt, aber aich den Hidden state zurÃ¼ck geben kann"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2ZzbyYX_RnV"
      },
      "source": [
        "class CustomRNNModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, rnn_units, rnn_layer_type = tf.keras.layers.GRU):\n",
        "        super().__init__(self)\n",
        "        # Put layers here. We will call them manually but store them here\n",
        "        self.rnn_layer = rnn_layer_type(rnn_units, return_sequences=True, return_state=True)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
        "\n",
        "    def call(self, inputs, states=None, return_state=False, training=False):\n",
        "        # Here we put our input through all out layers\n",
        "        x = tf.cast(inputs, dtype=float)\n",
        "        if states is None:\n",
        "            # Get an initial kind of empty state\n",
        "            states = self.rnn_layer.get_initial_state(x)\n",
        "        \n",
        "        x, states = self.rnn_layer(x, initial_state=states, training=training)\n",
        "        x = self.dense(x, training=training)\n",
        "\n",
        "        if return_state:\n",
        "            return x, states\n",
        "        else:\n",
        "            return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fiFktPV_RnV"
      },
      "source": [
        "literatur_model = CustomRNNModel(vocab_size=vocab_size, rnn_units=rnn_units)\n",
        "\n",
        "input_example_batch = X_train[0]\n",
        "input_example_batch = input_example_batch.reshape((1, *input_example_batch.shape))\n",
        "\n",
        "example_batch_predictions = literatur_model.predict(input_example_batch)\n",
        "print(input_example_batch.shape, y_train[0].shape, example_batch_predictions.shape)\n",
        "\n",
        "print(\"Test sequence:\", \"\\n\", \"-\" * 25, \"\\n\", untokenize(one_hot.decode(X_train[0])), \"\\n\", \"-\"*25)\n",
        "print(\"Expected result:\", \"\\n\", \"-\" * 25, \"\\n\", untokenize(one_hot.decode(y_train[0])), \"\\n\", \"-\"*25)\n",
        "print(\"Untrained prediction:\", \"\\n\", \"-\" * 25, \"\\n\", untokenize(one_hot.decode(example_batch_predictions[0])), \"\\n\", \"-\"*25)\n",
        "\n",
        "literatur_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "literatur_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QuI2o2c_RnV"
      },
      "source": [
        "t1 = time.time()\n",
        "hist_custom = literatur_model.fit(X_train, y_train,\n",
        "                           batch_size=BATCH_SIZE,\n",
        "                           epochs=EPOCHS,\n",
        "                           validation_data=(X_val, y_val))\n",
        "t2 = time.time()\n",
        "\n",
        "print(\"Training took:\", timedelta(seconds=t2-t1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYhQtFyT_RnW"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1)\n",
        "\n",
        "ax.plot(hist_custom.history[\"loss\"], label='loss')\n",
        "ax.plot(hist_custom.history[\"accuracy\"], label='accuracy')\n",
        "ax.plot(hist_custom.history[\"val_loss\"], label='validation loss')\n",
        "ax.plot(hist_custom.history[\"val_accuracy\"], label='validation accuracy')\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "ax.legend()\n",
        "\n",
        "fig.set_size_inches(20, 10)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE7snkJg_RnW"
      },
      "source": [
        "def create_text(amount_symbols, init_text, text_model):    \n",
        "    # Tokenize text\n",
        "    ret = tokenize(init_text)\n",
        "    \n",
        "    states = None\n",
        "    current_char = one_hot.encode(ret, dtype=float)\n",
        "    # For some reason we have to add one dimension\n",
        "    current_char = current_char.reshape(1, *current_char.shape)\n",
        "    \n",
        "    for i in range(amount_symbols):\n",
        "        current_char, states = text_model(current_char, return_state = True, states = states)\n",
        "        # Only add last char if several got \n",
        "        ret.append(one_hot.decode(current_char[0])[-1])\n",
        "        \n",
        "    return untokenize(ret)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWQ-b8AS_RnW"
      },
      "source": [
        "created_text = create_text(250, \"Sport\", literatur_model)\n",
        "\n",
        "print(created_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6mdZV36_RnW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}