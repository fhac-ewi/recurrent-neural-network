{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "√úbung-RNN-L√∂sung.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fhac-ewi/recurrent-neural-network/blob/main/%C3%9Cbung_RNN_L%C3%B6sung.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYD6gvw1vwii"
      },
      "source": [
        "# √úbung 7 - Rekurrente neuronale Netze (RNNs)\n",
        "\n",
        "## In dieser √úbung ...\n",
        "... besch√§ftigen wir uns mit rekurrenten neuronalen Netzen, die unter anderem f√ºr die Textvorhersage (`text prediction`) eingesetzt werden k√∂nnen. Sie werden ein eigenes Modell zur Vorhersage weiterer Buchstaben (Zeichen) zu einer gegebenen Buchstabensequenz erstellen.\n",
        "\n",
        "Dazu werden Sie die drei aus der Vorlesung bekannten Varianten von RNNs (Standard, LSTM und GRU) mit Keras implementieren und die Genauigkeit (Accuracy) der Netze miteinander vergleichen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a_ZEFJfHuuF"
      },
      "source": [
        "## 7.0 Vorbereitung\n",
        "\n",
        "In diesem Abschnitt m√ºssen Sie nichts programmieren! üéâ\n",
        "\n",
        "Wir haben bereits alle notwendigen Imports f√ºr diese √úbung hinzugef√ºgt, sodass Sie direkt starten k√∂nnen. Sie m√ºssen lediglich die GPU Unterst√ºtzung in Google Colab aktivieren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc_GxdsyIDYP"
      },
      "source": [
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Aktivieren Sie bitte die GPU Unterst√ºtzung in Google Colab. Wechseln Sie unter dem Reiter `Laufzeit` -> `Laufzeittyp √§ndern` von `None` auf `GPU` und best√§tigen Sie diese √Ñnderung.\n",
        "\n",
        "(2) F√ºhren Sie den folgenden Codezelle aus, um die erforderlichen Bibliotheken zu importieren und die GPU Unterst√ºtzung zu pr√ºfen. \n",
        "\n",
        "  * Hinweis: Wenn Sie dieses Notebook mit dem Direktlink von GitHub ge√∂ffnet haben, wird bei der erstmaligen Ausf√ºhrung eine Warnung angezeigt. Diese m√ºssen Sie durch den Klick auf `Trotzdem ausf√ºhren` best√§tigen. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-cFD9IFItkB",
        "outputId": "57de87f7-1e81-4e3c-ff43-1cbf7a8b1d64"
      },
      "source": [
        "# Import everything needed for this exercise \n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime, timedelta\n",
        "from termcolor import colored\n",
        "\n",
        "print(f\"Keras Version: {keras.__version__}; Tensorflow version: {tf.__version__}; NumPy version: {np.__version__}; Python version: \", \".\".join(str(x) for x in sys.version_info[:3]))\n",
        "\n",
        "# Reset random number generators\n",
        "seed = 1337\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Check GPU support\n",
        "from tensorflow.python.client import device_lib\n",
        "physical_devices = device_lib.list_local_devices()\n",
        "print(\"You are using\", len(physical_devices), \"local devises.\", len([x for x in physical_devices if x.device_type == \"GPU\"]), \"are GPUs\")\n",
        "for i, d in enumerate(physical_devices):\n",
        "    print(\"  ->Device\", i+1, \"is a\", d.device_type, \"=>\", d.physical_device_desc if len(d.physical_device_desc) > 0 else d.name)\n",
        "\n",
        "if len([x for x in physical_devices if x.device_type == \"GPU\"]) == 0:\n",
        "  raise Exception(\"Please enable GPU support before using this notebook. See here: [Runtime] -> [Change runtime type]\")    \n",
        "\n",
        "print(\"\\nüéâüéâüéâ You are ready to go! üéâüéâüéâ\")  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keras Version: 2.4.3; Tensorflow version: 2.4.1; NumPy version: 1.19.5; Python version:  3.7.10\n",
            "You are using 2 local devises. 1 are GPUs\n",
            "  ->Device 1 is a CPU => /device:CPU:0\n",
            "  ->Device 2 is a GPU => device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "\n",
            "üéâüéâüéâ You are ready to go! üéâüéâüéâ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1CXeYPHyywV"
      },
      "source": [
        "## 7.1 One Hot Kodierung\n",
        "\n",
        "Wir haben in der Vorlesung die One Hot Kodierung (1-aus-n-Code) kennen gelernt. Diese erm√∂glicht es Zeichen eines Alphabets als Vektoren darzustellen. \n",
        "\n",
        "F√ºr ein Alphabet mit `n` einzigartigen Zeichen wird ein Vektor der L√§nge `n` ben√∂tigt. Jedes einzigartige Zeichen wird hierbei als Einheitsvektor definiert. Eine Zeichensequenz mit `m` Zeichen werden als `m` Vektoren mit jeweils der L√§nge `n` dargestellt.  \n",
        "\n",
        "**Hinweis** Die vorliegende Implementierung ist f√ºr den Umgang mit Zeichen au√üerhalb des Alphabets konzipiert. Deshalb wird zur Darstellung eines Alphabets mit `n` einzigartigen Zeichen ein Vektor der L√§nge `n+1` erstellt. Alle Zeichen au√üerhalb des Alphabets werden durch das `unknown_token` ersetzt. \n",
        "\n",
        "F√ºr das Training unseres Netzes werden wir die One Hot Kodierung zur Umwandlung eines Textes in Trainingsdaten nutzen. (Aufgabe 7.2)\n",
        "\n",
        "* Hinweis: F√ºr weitere Informationen zur One Hot Kodierun schlagen Sie diese in der Vorlesung nach oder benutzen Sie das [Internet](https://de.wikipedia.org/wiki/1-aus-n-Code)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miApcJctvteM"
      },
      "source": [
        "class OneHot(object):\n",
        "    def __init__(self, tokens, unknown_token = \"[UNKNOWN]\"):\n",
        "        '''\n",
        "        tokens: The tokens you want to be able to encode and decode\n",
        "        unknown_token: The token to be used when decoding and the net wants to use a not known char\n",
        "        '''\n",
        "        self.tokens = tokens\n",
        "        self.unknown_token = unknown_token\n",
        "        # Store a bidirectional dictionary containing the characters\n",
        "        self.char_to_index = dict((token, i + 1) for i, token in enumerate(self.tokens))\n",
        "        self.index_to_char = dict((i + 1, token) for i, token in enumerate(self.tokens))\n",
        "        pass\n",
        "\n",
        "    def encode(self, text_as_tokens, dtype=np.bool_):\n",
        "        '''\n",
        "        text_as_tokens: List of tokens\n",
        "        '''\n",
        "        # Create the encoding matrix\n",
        "        enc = np.empty((len(text_as_tokens), len(self.tokens) + 1), dtype=dtype)\n",
        "        for i, token in enumerate(text_as_tokens):\n",
        "            # Encode every char\n",
        "            enc[i] = self.encode_token(token=token, l=len(self.tokens) + 1, dtype=dtype)\n",
        "        return enc\n",
        "    \n",
        "    def encode_token(self, token, l, dtype=np.bool_):\n",
        "        '''\n",
        "        token: Single token\n",
        "        l: length of array to be returned. At position zero it is stored if the char is unknown\n",
        "        '''\n",
        "        ret = np.zeros((1, l), dtype=dtype)\n",
        "        if token not in self.char_to_index:\n",
        "            ret[0, 0] = 1\n",
        "        else:\n",
        "            ret[0, self.char_to_index[token]] = 1\n",
        "        return ret\n",
        "    \n",
        "    def decode(self, mat, unknown_token=None):         \n",
        "        '''\n",
        "        mat: matrix to be decoded. Has to be of shape (len_of_text, vocab_size)\n",
        "        unknown_token: Unknown token. If none uses the one from __init__\n",
        "        '''\n",
        "        return [self.decode_token(mat[x]) for x in range(mat.shape[0])]\n",
        "    \n",
        "    def decode_token(self, vec, unknown_token=None):\n",
        "        '''\n",
        "        vec: Vector that should be decoded. Has to be on vocab length\n",
        "        unknown_token: Unknown token. If none uses the one from __init__\n",
        "        '''\n",
        "        if unknown_token is None:\n",
        "            unknown_token = self.unknown_token\n",
        "        if isinstance(vec, tf.Tensor):\n",
        "            vec = vec.numpy()\n",
        "        if isinstance(vec, np.ndarray):\n",
        "            # Use argmax since this will be used in the model created later\n",
        "            am = np.argmax(vec)\n",
        "        else:\n",
        "            am = vec\n",
        "        if am == 0:\n",
        "            return unknown_token\n",
        "        return self.index_to_char[am]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9nyVSBS_RnK"
      },
      "source": [
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Untersuchen Sie gegebene Klasse zur One Hot Kodierung und die Funktion der einzelnen Methoden. \n",
        "\n",
        "(2) Erstellen Sie f√ºr das folgendes Alphabet `HWedlor` eine Instanz der Klasse `OneHot`. \n",
        "\n",
        "(3) Kodieren Sie nun die Zeichenfolge `Hello World!` mit der One Hot Kodierung. Wie wird das Zeichen `H` dargestellt? Geben Sie die Dimensionen des Vektors an.\n",
        "\n",
        "* Hinweis: Sie k√∂nnen zur Umwandlung des Strings in eine Liste von Zeichen die Funktion `tokenize` verwenden. Dies ist aber nicht zwingend erforderlich, da Python den String automatisch als Liste interpretieren kann."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXopuHLJadWN"
      },
      "source": [
        "> <Antwort hier einf√ºgen>\n",
        "\n",
        "> **Musterl√∂sung:** Das Zeichen `H` wird als Vektor `[False  True False False False False False False]` \n",
        "dargestellt. Die Dimension ist `1x8`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jCputAba8UN"
      },
      "source": [
        "(4) Wandeln Sie die kodierte Zeichenfolge zur√ºck in einen f√ºr Menschen lesbaren Text. Entspricht der zur√ºckgewandelte Text dem urspr√ºnglichen Input? Falls nicht, beschreiben Sie die Ursache.\n",
        "\n",
        "* Hinweis: F√ºr eine sch√∂nere Ausgabe kann der enkodierte Text mit der Funktion `untokenize` in einen String gewandelt werden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPiAwayxbi16"
      },
      "source": [
        "> <Antwort hier einf√ºgen>\n",
        "\n",
        "> **Musterl√∂sung:** Der urspr√ºngliche Text und der kodierte und dekodierte Text ist nicht mehr identisch, da zwei Zeichen (Leerzeichen, Ausrufezeichen) nicht im Alphabet vorhanden sind. Durch Hinzuf√ºgen dieser Zeichen ins Alphabet w√ºrde man den urspr√ºnglichen Text erhalten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjFH6Rbeab4P",
        "outputId": "ade81b82-06ee-4a46-fad4-5ba076a31df5"
      },
      "source": [
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    Converts the given text (string) in a list of chars.\n",
        "    \"\"\"\n",
        "    return list(text)\n",
        "\n",
        "def untokenize(tokens):\n",
        "    \"\"\"\n",
        "    Converts the given tokens (list of chars) in a string.\n",
        "    \"\"\"\n",
        "    return \"\".join(tokens)\n",
        "\n",
        "tokens = 'HWedlor'\n",
        "\n",
        "# code here\n",
        "one_hot = OneHot(tokens=tokens)\n",
        "\n",
        "text='Hello World!'\n",
        "\n",
        "coded_text = one_hot.encode(text)\n",
        "print(\"Shape of coded text: \", coded_text.shape)\n",
        "print(\"H coded (first letter in coded text): \", coded_text[0])\n",
        "\n",
        "encoded_text = one_hot.decode(coded_text)\n",
        "\n",
        "print(untokenize(encoded_text))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of coded text:  (12, 8)\n",
            "H coded (first letter in coded text):  [False  True False False False False False False]\n",
            "Hello[UNKNOWN]World[UNKNOWN]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WglUJhhgyWSs"
      },
      "source": [
        "## 7.2 Datensatz vorbereiten\n",
        "\n",
        "In dieser √úbung verwenden wir das Buch Shakespeare TODO als Datensatz zum Training und Test unserer Modelle. Ziel der Modelle ist die Vorhersage weiterer Zeichen zu einer gegebenen Zeichensequenz.\n",
        "\n",
        "In diesem Aufgabenteil werden die Daten eingelesen, mithilfe der One Hot Kodierung umgewandelt und anschlie√üend in Trainingsdaten und Validierungsdaten aufgeteilt.\n",
        "\n",
        "* Hinweis: Sie k√∂nnen theoretisch jeden beliebigen Text als Datensatz f√ºr das Training des Modells verwenden. (z.B. Harry Potter B√ºcher, Coronaschutzverordnungen, Nachrichtenartikel, ...)\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) F√ºhren Sie die folgende Codezelle aus, um das Buch Shakespeare TODO einzulesen. Untersuchen Sie den Datensatz, indem Sie einen kurzen Auszug des Textes ausgeben.\n",
        "\n",
        "(2) Erstellen Sie aus dem Text das Alphabet (`tokens`) und geben die L√§nge aus. Das Alphabet soll alle Zeichen des Textes enthalten.\n",
        "\n",
        "* Hinweis: Sie k√∂nnen den `text` mit der Funktion `tokenize` in eine Liste umwandeln. Dieser kann dann zu einem [Set](https://docs.python.org/3/tutorial/datastructures.html#sets) gewandelt werden.\n",
        "\n",
        "(3) Erstellen Sie f√ºr das Alphabet eine One Hot Kodierung und wenden diese auf den `text` an. Nutzen Sie dazu Ihre die Erkentnisse aus Aufgabe 7.1.\n",
        "\n",
        "(4) Teilen Sie den kodierten Text in Sequenzen auf. Wie w√ºrden Sie die L√§nge der einzelnen Sequenzen w√§hlen? \n",
        "Verwenden Sie dazu die Funktion vorgegebene Funktion `sequenze_split`.\n",
        "\n",
        "* Erkl√§rung: Wieso wird der Text in Sequenzen gesplittet?\n",
        "</br>TODO Wieso machen wir das?\n",
        "\n",
        "* Hinweis: Die Sequenzen sollten lang genug sein, dass das RNN Zusammenh√§nge in einem Satz (und ggf. dar√ºber hinaus) erlenen kann. Die Sequenzl√§nge sollte kurz genug sein, damit eine ausreichende Anzahl f√ºr das Training vorhanden ist.\n",
        "\n",
        "TODO RIOT Hinweis mit unserer Sequenzl√§nge.\n",
        "\n",
        "(5) Erstellen Sie nun aus den sequenzierten Daten das Feature `X` und das Label `y`. F√ºr die Vorhersage von einzelnen Zeichen ist jeweils das n√§chste Zeichen das Label des vorherigen Zeichens. Das Label `y` wird deshalb aus den gleichen Werte des Features `X` gebildet, ist jedoch um +1 verschoben. \n",
        "\n",
        "\n",
        "* Beispiel: Die Sequenz `Hello World!` kann in **X** `Hello World` mit dem zugeh√∂rigen Label **y** `ello World!` aufgeteilt werden.\n",
        "* Hinweis: Untersuchen Sie die R√ºckgabe der Funktion `sequenze_split`. In welcher der drei Komponenten m√ºssen Sie die Verschiebung vornehmen.\n",
        "\n",
        "(6) Konvertieren Sie nun die Daten in ein Trainings- und Validierungsset. Nutzen Sie daf√ºr die Funktion `train_test_split` (Eine Dokumentation finden Sie [hier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN0KsVCb_Rm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd610da-2465-43a5-fa88-14d4be040394"
      },
      "source": [
        "# maximum text length \n",
        "# 1. Protection against \"OutOfMemory\" (poor RAM üò•)\n",
        "# 2. Adjustment for making training faster (but you will gain less accuracy)\n",
        "MAX_TEXT_LEN = 700_000 \n",
        "\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "# TODO path_to_file = tf.keras.utils.get_file('german_news.txt', 'https://raw.githubusercontent.com/tblock/10kGNAD/master/articles.csv') # Taken from https://github.com/tblock/10kGNAD\n",
        "\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print(f'Length of text: {len(text)} characters')\n",
        "if len(text) > MAX_TEXT_LEN:\n",
        "    print(\"Text is too long. Cutting it to\", MAX_TEXT_LEN, f\"characters. That is {100 * MAX_TEXT_LEN / len(text):6.2f} %\")\n",
        "    text = text[:MAX_TEXT_LEN]\n",
        "\n",
        "# helper function for 7.2.4\n",
        "def sequenze_split(coded_text, sequence_len):\n",
        "    \"\"\"\n",
        "    Splits a given coded text (text converted with OneHot) into multiple subsequenzes\n",
        "    \"\"\"\n",
        "    target_shape = (int(coded_text.shape[0] / (sequence_len + 1)) , (sequence_len + 1) , coded_text.shape[1])\n",
        "    coded_text_seq = np.empty(target_shape, dtype=coded_text.dtype)\n",
        "    for s in range(coded_text_seq.shape[0]):\n",
        "        coded_text_seq[s] = coded_text[s * (sequence_len + 1):(s + 1) * (sequence_len + 1)]\n",
        "\n",
        "    # returns 3D matrix (sequences, letters per sequence, letter as one hot coded vector)    \n",
        "    return coded_text_seq    \n",
        "\n",
        "# code here   \n",
        "# Aufgabe 7.2.1 \n",
        "print(\"Segment of text:\")\n",
        "print(\"-\" * 60)\n",
        "print(colored(text[:250], 'blue')) \n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Aufgabe 7.2.2 - Alphabet erstellen\n",
        "tokens = sorted(set(text))\n",
        "print(\"Length of raw text:\", len(text))\n",
        "print(\"Numbers of tokens (unique letters): \", len(tokens))\n",
        "\n",
        "\n",
        "# Aufgabe 7.2.3 - One Hot\n",
        "one_hot = OneHot(tokens=tokens)\n",
        "coded_text = one_hot.encode(text)\n",
        "print(\"Shape of coded text: \", coded_text.shape)\n",
        "\n",
        "# Aufgabe 7.2.4 - Aufteilung in Sequenzen\n",
        "sequence_len = 150\n",
        "coded_text_seq = sequenze_split(coded_text, sequence_len)\n",
        "print(\"Shape of coded text split into sequences\", coded_text_seq.shape)\n",
        "\n",
        "# Aufgabe 7.2.5\n",
        "X = coded_text_seq[:, :-1]\n",
        "y = coded_text_seq[:, 1:]\n",
        "\n",
        "# Aufgabe 7.2.6\n",
        "validation_size = 1/4\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=validation_size)\n",
        "\n",
        "print(\"X_train:\", X_train.shape, X_train.dtype)\n",
        "print(\"y_train:\", y_train.shape, y_train.dtype)\n",
        "print(\"X_val  :\", X_val.shape, X_val.dtype)\n",
        "print(\"y_val  :\", y_val.shape, y_val.dtype)\n",
        "\n",
        "print(\"-\" * 40)\n",
        "print(colored(untokenize(one_hot.decode(X_train[0])), 'blue'))\n",
        "print(\"-\" * 40)\n",
        "print(colored(untokenize(one_hot.decode(y_train[0])), 'green'))\n",
        "print(\"-\" * 40)    "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n",
            "Text is too long. Cutting it to 700000 characters. That is  62.76 %\n",
            "Segment of text:\n",
            "------------------------------------------------------------\n",
            "\u001b[34mFirst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\u001b[0m\n",
            "------------------------------------------------------------\n",
            "Length of raw text: 700000\n",
            "Numbers of tokens (unique letters):  65\n",
            "Shape of coded text:  (700000, 66)\n",
            "Shape of coded text split into sequences (6930, 101, 66)\n",
            "X_train: (5197, 100, 66) bool\n",
            "y_train: (5197, 100, 66) bool\n",
            "X_val  : (1733, 100, 66) bool\n",
            "y_val  : (1733, 100, 66) bool\n",
            "----------------------------------------\n",
            "\u001b[34m spend another such a night,\n",
            "Though 'twere to buy a world of happy days,\n",
            "So full of dismal terror wa\u001b[0m\n",
            "----------------------------------------\n",
            "\u001b[32mspend another such a night,\n",
            "Though 'twere to buy a world of happy days,\n",
            "So full of dismal terror was\u001b[0m\n",
            "----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDvkDpWsysjl"
      },
      "source": [
        "üéâüéâüéâ **Geschafft!** üéâüéâüéâ\n",
        "\n",
        "Sie haben nun aus einem Buch Trainingsdaten f√ºr ein RNN zur Vorhersage von Zeichen erstellt! \n",
        "- Text einlesen\n",
        "- Text in Tokens umwandeln\n",
        "- Alphabet festlegen\n",
        "- One Hot Kodierung erstellen und anwenden\n",
        "- In Sequenzen aufteilen\n",
        "- `X` und `y` festlegen\n",
        "- Aufteilung in Training und Validierungsset\n",
        "\n",
        "... jetzt k√∂nnen Sie mit dem eigentlichen Modell fortfahren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOMFCH7V_RnM"
      },
      "source": [
        "## 7.3 RNN Modell erstellen\n",
        "\n",
        "In dieser √úbung wird nun das rekurrente neuronale Netz zur Vorhersage von Buchstaben zu einer gegebenen Sequenz erstellt. Das Training wird in der n√§chsten Aufgabenteil durchgef√ºhrt.\n",
        "\n",
        "In diesem Aufgabenteil wird ein Simple RNN (auch Vanilla bezeichnet) trainiert.\n",
        "\n",
        "Sie verwenden dazu ein *SimpleRNN* (Link) \n",
        "\n",
        "Hier erstellen wir das eigentliche RNN. Hierf√ºr nutzen wir ein Sequential Model von Keras mit einem RNN und einem Dense Layer mit Softmax zum erstellen der Ausgabe.\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Bestimmen Sie nun die Parameter, die f√ºr das Modell ben√∂tigt werden.\n",
        "- Shape der Eingabe/des Trainingdatensatzes. (Anzahl Zeichen, L√§nge eines vektorisierten Zeichens)\n",
        "- L√§nge des Alphabets (inklusive des `unknown_tokens`). Also die Anzahl der Tokens, die das Modell vorhersagen k√∂nnen soll.\n",
        "  \n",
        "\n",
        "(2) Erstellen Sie das entsprechende [Sequential](https://keras.io/api/models/sequential/) Modell und f√ºgen folgende Schichten hinzu:\n",
        "- [SimpleRNN](https://keras.io/api/layers/recurrent_layers/simple_rnn/) mit 1024 Units als Output Space (= Gr√∂√üe des Hidden State), dem Parameter `return_sequences=true` und der Shape der Eingabe. \n",
        "- [Dense](https://keras.io/api/layers/core_layers/dense/) mit der Anzahl der Tokens und der Aktivierungsfunktion `softmax`.\n",
        "\n",
        "Kompilieren Sie anschlie√üend das Modell mit der `categorical_crossentropy` Loss Function, dem `Adam` Optimizer und f√ºgen als Metrics die `accuracy` hinzu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Uh7RmR_RnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d549a89-24b0-4ab1-8950-62a125e0f832"
      },
      "source": [
        "# code here\n",
        "# Aufgabe 7.3.1\n",
        "# Length of the vocabulary in chars\n",
        "vocab_size = X_train.shape[-1]\n",
        "print(\"Numbers of unique tokens: \", vocab_size)\n",
        "\n",
        "# The input shape\n",
        "input_shape = X_train.shape[1:]\n",
        "print(\"Input shape: \", input_shape)\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 2048\n",
        "\n",
        "# Aufgabe 7.3.2 - SimpleRNN\n",
        "model = tf.keras.Sequential(name=\"SimpleRNN_Model\")\n",
        "model.add(tf.keras.layers.SimpleRNN(rnn_units, return_sequences=True, input_shape=input_shape, name=\"The_Brain\"))\n",
        "model.add(tf.keras.layers.Dense(vocab_size, activation='softmax', name=\"The_Hand\"))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Zusatz\n",
        "input_example_batch = X_train[0]\n",
        "input_example_batch = input_example_batch.reshape((1, *input_example_batch.shape))\n",
        "\n",
        "example_batch_predictions = model.predict(input_example_batch)\n",
        "print(input_example_batch.shape, y_train[0].shape, example_batch_predictions.shape)\n",
        "\n",
        "print(\"Test sequence:\", \"\\n\", \"-\" * 40, \"\\n\", colored(untokenize(one_hot.decode(X_train[0])), 'blue'), \"\\n\", \"-\"*40)\n",
        "print(\"Expected result:\", \"\\n\", \"-\" * 40, \"\\n\", colored(untokenize(one_hot.decode(y_train[0])), 'green'), \"\\n\", \"-\"*40)\n",
        "print(\"Untrained prediction:\", \"\\n\", \"-\" * 40, \"\\n\", colored(untokenize(one_hot.decode(example_batch_predictions[0])), 'red'), \"\\n\", \"-\"*40)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numbers of unique tokens:  66\n",
            "Input shape:  (100, 66)\n",
            "Model: \"SimpleRNN_Model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "The_Brain (SimpleRNN)        (None, 100, 2048)         4331520   \n",
            "_________________________________________________________________\n",
            "The_Hand (Dense)             (None, 100, 66)           135234    \n",
            "=================================================================\n",
            "Total params: 4,466,754\n",
            "Trainable params: 4,466,754\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(1, 100, 66) (100, 66) (1, 100, 66)\n",
            "Test sequence: \n",
            " ---------------------------------------- \n",
            " \u001b[34m spend another such a night,\n",
            "Though 'twere to buy a world of happy days,\n",
            "So full of dismal terror wa\u001b[0m \n",
            " ----------------------------------------\n",
            "Expected result: \n",
            " ---------------------------------------- \n",
            " \u001b[32mspend another such a night,\n",
            "Though 'twere to buy a world of happy days,\n",
            "So full of dismal terror was\u001b[0m \n",
            " ----------------------------------------\n",
            "Untrained prediction: \n",
            " ---------------------------------------- \n",
            " \u001b[31mXWzma$XtC$;Bx\n",
            "dHwrbVyxC &IM,jtUB!f$WXhpCM?KBHLUL,OXTyHFbRq3m[UNKNOWN]bVjecx[UNKNOWN]?qOeIvUMMSYv L[UNKNOWN]rqqGmmA!Nb,IXwEiU\u001b[0m \n",
            " ----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axndj50eyWrw"
      },
      "source": [
        "## 7.4 RNN Modell trainieren\n",
        "\n",
        "\n",
        "TODO \n",
        "Nun gehts ans trainieren. Nutzen Sie f√ºr den Anfang eine kleine Anzahl an epochen um herauszufinden wie viele Sie in einer ertragbaren Zeit machen k√∂nnen. Sollten Sie auf google Colab arbeiten k√∂nnte 20 hier ein guter Startwert sein\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Nutze die Fit methode deines models um es auf den ertellten Trainingsdaten zu trainieren. Wenn Sie validierungsdaten erzeugt haben k√∂nnen Sie diese bei validation_data angeben. Um die Trainingszeit kurz zu halten kann es auch Sinn ergeben hier eine batch_size anzugeben\n",
        "\n",
        "* Hinweis: Eine val_accuracy von circa 40% nach 10 Epochen oder von 50% nach 20 Epochen ist f√ºr dieses Modell nat√ºrlich noch lange nicht gut, aber ganz passabel. Erwarten Sie bitte nicht zu viel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_SVsygGOYVa"
      },
      "source": [
        "EPOCHS = 20\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGpNzqcuyW5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "771d16c5-86c6-4c0b-b550-c4e0450bd113"
      },
      "source": [
        "t1 = time.time()\n",
        "hist = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=EPOCHS,\n",
        "                  validation_data=(X_val, y_val))\n",
        "t2 = time.time()\n",
        "\n",
        "print(\"Training took: \", timedelta(seconds=t2-t1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "163/163 [==============================] - 16s 95ms/step - loss: 3.6712 - accuracy: 0.1335 - val_loss: 3.2370 - val_accuracy: 0.1543\n",
            "Epoch 2/20\n",
            "163/163 [==============================] - 15s 90ms/step - loss: 3.1607 - accuracy: 0.1832 - val_loss: 2.8161 - val_accuracy: 0.2740\n",
            "Epoch 3/20\n",
            "163/163 [==============================] - 15s 91ms/step - loss: 2.9168 - accuracy: 0.2416 - val_loss: 2.7301 - val_accuracy: 0.2609\n",
            "Epoch 4/20\n",
            "163/163 [==============================] - 15s 91ms/step - loss: 2.7170 - accuracy: 0.2675 - val_loss: 2.5407 - val_accuracy: 0.2996\n",
            "Epoch 5/20\n",
            "163/163 [==============================] - 15s 92ms/step - loss: 2.5412 - accuracy: 0.2997 - val_loss: 2.5030 - val_accuracy: 0.3133\n",
            "Epoch 6/20\n",
            "163/163 [==============================] - 15s 91ms/step - loss: 2.4368 - accuracy: 0.3204 - val_loss: 2.3879 - val_accuracy: 0.3279\n",
            "Epoch 7/20\n",
            "163/163 [==============================] - 15s 90ms/step - loss: 2.4484 - accuracy: 0.3210 - val_loss: 2.3650 - val_accuracy: 0.3319\n",
            "Epoch 8/20\n",
            "163/163 [==============================] - 15s 91ms/step - loss: 2.3505 - accuracy: 0.3399 - val_loss: 2.3292 - val_accuracy: 0.3365\n",
            "Epoch 9/20\n",
            "163/163 [==============================] - 15s 90ms/step - loss: 2.2924 - accuracy: 0.3518 - val_loss: 2.2838 - val_accuracy: 0.3565\n",
            "Epoch 10/20\n",
            "163/163 [==============================] - 15s 92ms/step - loss: 2.2602 - accuracy: 0.3615 - val_loss: 2.2903 - val_accuracy: 0.3406\n",
            "Epoch 11/20\n",
            "163/163 [==============================] - ETA: 0s - loss: 2.2338 - accuracy: 0.3650"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwFD7439_RnO"
      },
      "source": [
        "(2) Plotten Sie accuracy und loss √ºber die Epochen um bewerten zu k√∂nnen wie gut das Training lief"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCn3o8K9_RnO"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1)\n",
        "\n",
        "ax.plot(hist.history[\"loss\"], label='loss')\n",
        "ax.plot(hist.history[\"accuracy\"], label='accuracy')\n",
        "ax.plot(hist.history[\"val_loss\"], label='validation loss')\n",
        "ax.plot(hist.history[\"val_accuracy\"], label='validation accuracy')\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "ax.legend()\n",
        "\n",
        "fig.set_size_inches(20, 10)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhQ4HP55Fidk"
      },
      "source": [
        "# Zusatz\n",
        "input_example_batch = X_train[0]\n",
        "input_example_batch = input_example_batch.reshape((1, *input_example_batch.shape))\n",
        "\n",
        "example_batch_predictions = model.predict(input_example_batch)\n",
        "print(input_example_batch.shape, y_train[0].shape, example_batch_predictions.shape)\n",
        "\n",
        "print(\"Test sequence:\", \"\\n\", \"-\" * 40, \"\\n\", colored(untokenize(one_hot.decode(X_train[0])), 'blue'), \"\\n\", \"-\"*40)\n",
        "print(\"Expected result:\", \"\\n\", \"-\" * 40, \"\\n\", colored(untokenize(one_hot.decode(y_train[0])), 'green'), \"\\n\", \"-\"*40)\n",
        "print(\"Trained prediction:\", \"\\n\", \"-\" * 40, \"\\n\", colored(untokenize(one_hot.decode(example_batch_predictions[0])), 'red'), \"\\n\", \"-\"*40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sslY_jvfwHN-"
      },
      "source": [
        "TODO Was hat er gelernt?\n",
        "\n",
        "- Gro√üschreibung nach Punkte\n",
        "- W√∂rter\n",
        "- ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxNyKthd_RnP"
      },
      "source": [
        "## x.5 Text prediction\n",
        "\n",
        "(1) Schreiben Sie eine Methode, die f√ºr einen gegebenen Text das n√§chste Zeichen prognostiziert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3wVdygn_RnQ"
      },
      "source": [
        "def predict(txt, one_hot, trainied_model):\n",
        "    encoded_txt = one_hot.encode(tokenize(txt))\n",
        "    prediction = trainied_model.predict(encoded_txt.reshape((1, *encoded_txt.shape)))\n",
        "    return untokenize(one_hot.decode(prediction[0]))[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67T8xcMS_RnQ"
      },
      "source": [
        "(2) *Optional:* Nutzen Sie ipywidgets um live vorschl√§ge zur√ºck zu geben"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApEZl0IK_RnQ"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ENo5TOT_RnR"
      },
      "source": [
        "def verbose_prediction(txt, one_hot, trainied_model):\n",
        "    if len(txt) == 0:\n",
        "        txt = \" \"\n",
        "    prediction = predict(txt=txt, one_hot=one_hot, trainied_model=trainied_model)\n",
        "    print(f\"I think the next will be \\\"{prediction}\\\" after you said \\\"{txt}\\\"\")\n",
        "\n",
        "w = widgets.interactive(verbose_prediction,\n",
        "                        txt=widgets.Text(value='Hello Worl', placeholder='Type something', description='Your text:', disabled=False),\n",
        "                        one_hot=widgets.fixed(one_hot),\n",
        "                        trainied_model=widgets.fixed(model),\n",
        "                       )\n",
        "\n",
        "verbose_prediction(\"Spor\", one_hot=one_hot, trainied_model=model)\n",
        "verbose_prediction(\"Fu√üba\", one_hot=one_hot, trainied_model=model)\n",
        "\n",
        "display(w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d7pKNy1ycN7"
      },
      "source": [
        "## x.6 *Optional* Vergleich mit LSTM und GRU und ...\n",
        "\n",
        "Trainieren Sie nun modelle mit LSTM und GRU oder anderen Architekturen und vergleichen Sie lernperformance und Ergebnisse. Was f√§llt Ihnen auf?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IehQ7h3uyeY6"
      },
      "source": [
        "model_lstm = tf.keras.Sequential(name=\"LSTM_Model\")\n",
        "model_lstm.add(tf.keras.layers.LSTM(rnn_units, return_sequences=True, input_shape=input_shape, name=\"The_Brain\"))\n",
        "model_lstm.add(tf.keras.layers.Dense(vocab_size, activation='softmax', name=\"The_Hand\"))\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_lstm.summary()\n",
        "\n",
        "model_gru = tf.keras.Sequential(name=\"GRU_Model\")\n",
        "model_gru.add(tf.keras.layers.LSTM(rnn_units, return_sequences=True, input_shape=input_shape, name=\"The_Brain\"))\n",
        "model_gru.add(tf.keras.layers.Dense(vocab_size, activation='softmax', name=\"The_Hand\"))\n",
        "model_gru.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_gru.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knXfKSKy_RnS"
      },
      "source": [
        "t1 = time.time()\n",
        "hist_lstm = model_lstm.fit(X_train, y_train,\n",
        "                           batch_size=BATCH_SIZE,\n",
        "                           epochs=EPOCHS,\n",
        "                           validation_data=(X_val, y_val))\n",
        "t2 = time.time()\n",
        "t_lstm = t2 - t1\n",
        "\n",
        "t1 = time.time()\n",
        "hist_gru = model_gru.fit(X_train, y_train,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         epochs=EPOCHS,\n",
        "                         validation_data=(X_val, y_val))\n",
        "t2 = time.time()\n",
        "t_gru = t2 - t1\n",
        "\n",
        "print(\"LSTM Training took:\", timedelta(seconds=t_lstm))\n",
        "print(\"GRU  Training took:\", timedelta(seconds=t_gru))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HlKt70B_RnT"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1)\n",
        "\n",
        "for n, h in [(\"simple rnn\", hist), (\"lstm\", hist_lstm), (\"gru\", hist_gru)]:\n",
        "\n",
        "    ax.plot(h.history[\"loss\"], label=f'{n} loss')\n",
        "    ax.plot(h.history[\"accuracy\"], label=f'{n} accuracy')\n",
        "    ax.plot(h.history[\"val_loss\"], label=f'{n} validation loss')\n",
        "    ax.plot(h.history[\"val_accuracy\"], label=f'{n} validation accuracy')\n",
        "\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "ax.legend()\n",
        "\n",
        "fig.set_size_inches(20, 10)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMWgGgRZ_RnT"
      },
      "source": [
        "## x.7 *Noch Optionaler* Ist das Netz jetzt ein Schriftsteller?\n",
        "\n",
        "Was m√ºsste man √§ndern um nun ein ganzes Buch erstellen zu lassen? Glauben Sie das Ergebniss w√§re lesbar?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wyhz--mz_RnT"
      },
      "source": [
        "Hierf√ºr wollen wir wenn m√∂glich beliebig viele Zeichen generieren, dabei den hidden state behalten und nicht konstant das bisher geschriebene als Input wieder einf√ºgen. Deshalb nutzen wir hier eine eigene Klasse f√ºr das Netz, die dann die Layer enth√§lt, aber aich den Hidden state zur√ºck geben kann"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2ZzbyYX_RnV"
      },
      "source": [
        "class CustomRNNModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, rnn_units, rnn_layer_type = tf.keras.layers.GRU):\n",
        "        super().__init__(self)\n",
        "        # Put layers here. We will call them manually but store them here\n",
        "        self.rnn_layer = rnn_layer_type(rnn_units, return_sequences=True, return_state=True)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
        "\n",
        "    def call(self, inputs, states=None, return_state=False, training=False):\n",
        "        # Here we put our input through all out layers\n",
        "        x = tf.cast(inputs, dtype=float)\n",
        "        if states is None:\n",
        "            # Get an initial kind of empty state\n",
        "            states = self.rnn_layer.get_initial_state(x)\n",
        "        \n",
        "        x, states = self.rnn_layer(x, initial_state=states, training=training)\n",
        "        x = self.dense(x, training=training)\n",
        "\n",
        "        if return_state:\n",
        "            return x, states\n",
        "        else:\n",
        "            return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fiFktPV_RnV"
      },
      "source": [
        "literatur_model = CustomRNNModel(vocab_size=vocab_size, rnn_units=rnn_units)\n",
        "\n",
        "input_example_batch = X_train[0]\n",
        "input_example_batch = input_example_batch.reshape((1, *input_example_batch.shape))\n",
        "\n",
        "example_batch_predictions = literatur_model.predict(input_example_batch)\n",
        "print(input_example_batch.shape, y_train[0].shape, example_batch_predictions.shape)\n",
        "\n",
        "print(\"Test sequence:\", \"\\n\", \"-\" * 25, \"\\n\", untokenize(one_hot.decode(X_train[0])), \"\\n\", \"-\"*25)\n",
        "print(\"Expected result:\", \"\\n\", \"-\" * 25, \"\\n\", untokenize(one_hot.decode(y_train[0])), \"\\n\", \"-\"*25)\n",
        "print(\"Untrained prediction:\", \"\\n\", \"-\" * 25, \"\\n\", untokenize(one_hot.decode(example_batch_predictions[0])), \"\\n\", \"-\"*25)\n",
        "\n",
        "literatur_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "literatur_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QuI2o2c_RnV"
      },
      "source": [
        "t1 = time.time()\n",
        "hist_custom = literatur_model.fit(X_train, y_train,\n",
        "                           batch_size=BATCH_SIZE,\n",
        "                           epochs=EPOCHS,\n",
        "                           validation_data=(X_val, y_val))\n",
        "t2 = time.time()\n",
        "\n",
        "print(\"Training took:\", timedelta(seconds=t2-t1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYhQtFyT_RnW"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1)\n",
        "\n",
        "ax.plot(hist_custom.history[\"loss\"], label='loss')\n",
        "ax.plot(hist_custom.history[\"accuracy\"], label='accuracy')\n",
        "ax.plot(hist_custom.history[\"val_loss\"], label='validation loss')\n",
        "ax.plot(hist_custom.history[\"val_accuracy\"], label='validation accuracy')\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "ax.legend()\n",
        "\n",
        "fig.set_size_inches(20, 10)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE7snkJg_RnW"
      },
      "source": [
        "def create_text(amount_symbols, init_text, text_model):    \n",
        "    # Tokenize text\n",
        "    ret = tokenize(init_text)\n",
        "    \n",
        "    states = None\n",
        "    current_char = one_hot.encode(ret, dtype=float)\n",
        "    # For some reason we have to add one dimension\n",
        "    current_char = current_char.reshape(1, *current_char.shape)\n",
        "    \n",
        "    for i in range(amount_symbols):\n",
        "        current_char, states = text_model(current_char, return_state = True, states = states)\n",
        "        # Only add last char if several got \n",
        "        ret.append(one_hot.decode(current_char[0])[-1])\n",
        "        \n",
        "    return untokenize(ret)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWQ-b8AS_RnW"
      },
      "source": [
        "created_text = create_text(250, \"Sport\", literatur_model)\n",
        "\n",
        "print(created_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6mdZV36_RnW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}