{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Uebung-7-RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fhac-ewi/recurrent-neural-network/blob/main/Uebung_7_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYD6gvw1vwii"
      },
      "source": [
        "# √úbung 7 - Rekurrente neuronale Netze (RNNs)\n",
        "\n",
        "## In dieser √úbung ...\n",
        "... besch√§ftigen wir uns mit rekurrenten neuronalen Netzen, die unter anderem f√ºr die Textvorhersage (`text prediction`) eingesetzt werden k√∂nnen. In dieser √úbung werden Sie  ein eigenes Modell zur Vorhersage weiterer Buchstaben (Zeichen) zu einer gegebenen Buchstabensequenz erstellen. \n",
        "\n",
        "Dazu werden Sie einen Datensatz f√ºr das Training vorbereiten, ein Standard-RNN mithilfe von Keras implementieren und f√ºr die Vorhersage des n√§chsten Zeichens und sogar ganzen S√§tzen nutzen.\n",
        "\n",
        "Wenn Sie diese ersten Schritte geschafft haben und noch Zeit haben, d√ºrfen Sie die beiden weiteren Varianten (LSTM und GRU) implementieren und anschlie√üend die Genauigkeit (Accuracy) der Netze miteinander vergleichen. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a_ZEFJfHuuF"
      },
      "source": [
        "## 7.0 Vorbereitung\n",
        "\n",
        "In diesem Abschnitt m√ºssen Sie nichts programmieren! üéâ\n",
        "\n",
        "Wir haben bereits alle notwendigen Imports f√ºr diese √úbung hinzugef√ºgt, sodass Sie direkt starten k√∂nnen. Sie m√ºssen lediglich die GPU Unterst√ºtzung in Google Colab aktivieren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc_GxdsyIDYP"
      },
      "source": [
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Aktivieren Sie bitte die GPU Unterst√ºtzung in Google Colab. Wechseln Sie unter dem Reiter `Laufzeit` -> `Laufzeittyp √§ndern` von `None` auf `GPU` und best√§tigen Sie diese √Ñnderung.\n",
        "\n",
        "(2) F√ºhren Sie die folgende Codezelle aus, um die erforderlichen Bibliotheken zu importieren und die GPU Unterst√ºtzung zu pr√ºfen. \n",
        "\n",
        "  * Hinweis: Wenn Sie dieses Notebook mit dem Direktlink von GitHub ge√∂ffnet haben, wird bei der erstmaligen Ausf√ºhrung eine Warnung angezeigt. Diese m√ºssen Sie durch den Klick auf `Trotzdem ausf√ºhren` best√§tigen. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-cFD9IFItkB"
      },
      "source": [
        "# Import everything needed for this exercise \n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime, timedelta\n",
        "from termcolor import colored\n",
        "import logging\n",
        "\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "print(f\"Keras Version: {keras.__version__}; Tensorflow version: {tf.__version__}; NumPy version: {np.__version__}; Python version: \", \".\".join(str(x) for x in sys.version_info[:3]))\n",
        "\n",
        "# Reset random number generators\n",
        "seed = 1337\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Check GPU support\n",
        "from tensorflow.python.client import device_lib\n",
        "physical_devices = device_lib.list_local_devices()\n",
        "print(\"You are using\", len(physical_devices), \"local devises.\", len([x for x in physical_devices if x.device_type == \"GPU\"]), \"are GPUs\")\n",
        "for i, d in enumerate(physical_devices):\n",
        "    print(\"  -> Device\", i+1, \"is a\", d.device_type, \"=>\", d.physical_device_desc if len(d.physical_device_desc) > 0 else d.name)\n",
        "\n",
        "if len([x for x in physical_devices if x.device_type == \"GPU\"]) == 0:\n",
        "  raise Exception(\"Please enable GPU support before using this notebook. See here: [Runtime] -> [Change runtime type]\")    \n",
        "\n",
        "print(\"\\nüéâüéâüéâ You are ready to go! üéâüéâüéâ\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1CXeYPHyywV"
      },
      "source": [
        "## 7.1 One Hot Kodierung\n",
        "\n",
        "Wir haben in der Vorlesung die One Hot Kodierung (1-aus-n-Code) kennen gelernt. Diese erm√∂glicht es Zeichen eines Alphabets als Vektoren darzustellen. \n",
        "\n",
        "F√ºr ein Alphabet mit `n` einzigartigen Zeichen wird ein Vektor der L√§nge `n` ben√∂tigt. Jedes einzigartige Zeichen wird hierbei als Einheitsvektor definiert. Eine Zeichensequenz mit `m` Zeichen wird als `m` Vektoren mit jeweils der L√§nge `n` dargestellt.  \n",
        "\n",
        "**Hinweis** Die vorliegende Implementierung ist f√ºr den Umgang mit Zeichen au√üerhalb des Alphabets konzipiert. Deshalb wird zur Darstellung eines Alphabets mit `n` einzigartigen Zeichen ein Vektor der L√§nge `n+1` erstellt. Alle Zeichen au√üerhalb des Alphabets werden durch das `unknown_token` ersetzt. \n",
        "\n",
        "F√ºr das Training unseres Netzes werden wir die One Hot Kodierung zur Umwandlung eines Textes in Trainingsdaten nutzen. (Aufgabe 7.2)\n",
        "\n",
        "* Hinweis: F√ºr weitere Informationen zur One Hot Kodierun schlagen Sie diese in der Vorlesung nach oder benutzen Sie das [Internet](https://www.semanticscholar.org/search?q=one%20hot%20coder&sort=relevance)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miApcJctvteM"
      },
      "source": [
        "class OneHot(object):\n",
        "    def __init__(self, tokens, unknown_token = \"[UNKNOWN]\"):\n",
        "        '''\n",
        "        Creates a new instance of this class. \n",
        "\n",
        "        OneHot can be used to translate categorical data into vectors.\n",
        "\n",
        "        Parameters\n",
        "        tokens -- The tokens you want to be able to encode and decode\n",
        "        unknown_token -- The token to be used when decoding and the net wants to use a not known char\n",
        "        '''\n",
        "        self.tokens = tokens\n",
        "        self.unknown_token = unknown_token\n",
        "        # Store a bidirectional dictionary containing the characters\n",
        "        self.char_to_index = dict((token, i + 1) for i, token in enumerate(self.tokens))\n",
        "        self.index_to_char = dict((i + 1, token) for i, token in enumerate(self.tokens))\n",
        "        pass\n",
        "\n",
        "    def encode(self, text_as_tokens, dtype=np.bool_):\n",
        "        '''\n",
        "        Encodes a tokenized text into a matrix (each token as vector).\n",
        "\n",
        "        Parameters:\n",
        "        text_as_tokens -- List of tokens\n",
        "        dtype -- (optional) data type like int or bool for optimized performance\n",
        "\n",
        "        Returns:\n",
        "        np.array of OneHot encoded tokens (matrix)\n",
        "        '''\n",
        "        # Create the encoding matrix\n",
        "        enc = np.empty((len(text_as_tokens), len(self.tokens) + 1), dtype=dtype)\n",
        "        for i, token in enumerate(text_as_tokens):\n",
        "            # Encode every char\n",
        "            enc[i] = self.encode_token(token=token, dtype=dtype)\n",
        "        return enc\n",
        "    \n",
        "    def encode_token(self, token, dtype=np.bool_):\n",
        "        '''\n",
        "        Encodes a single token into a vector.\n",
        "\n",
        "        Parameters:\n",
        "        token -- Single token\n",
        "        dtype -- (optional) data type like int or bool for optimized performance\n",
        "\n",
        "        Returns:\n",
        "        np.array of OneHot encoded token (vector)\n",
        "        '''\n",
        "        l = len(self.tokens) + 1\n",
        "        ret = np.zeros((1, l), dtype=dtype)\n",
        "        if token not in self.char_to_index:\n",
        "            ret[0, 0] = 1\n",
        "        else:\n",
        "            ret[0, self.char_to_index[token]] = 1\n",
        "        return ret\n",
        "    \n",
        "    def decode(self, mat, unknown_token=None):         \n",
        "        '''\n",
        "        Decodes a matrix into an array of tokens.\n",
        "\n",
        "        Parameters:\n",
        "        mat -- matrix to be decoded. Has to be of shape (len_of_text, vocab_size)\n",
        "        unknown_token -- Unknown token. If none uses the one from __init__\n",
        "\n",
        "        Returns:\n",
        "        array of tokens (chars)\n",
        "        '''\n",
        "        return [self.decode_token(mat[x]) for x in range(mat.shape[0])]\n",
        "    \n",
        "    def decode_token(self, vec, unknown_token=None):\n",
        "        '''\n",
        "        Decodes a vector into a token.\n",
        "\n",
        "        Parameters:\n",
        "        vec -- Vector that should be decoded. Has to be on vocab length\n",
        "        unknown_token -- Unknown token. If none uses the one from __init__\n",
        "\n",
        "        Returns:\n",
        "        single token (char)\n",
        "        '''\n",
        "        if unknown_token is None:\n",
        "            unknown_token = self.unknown_token\n",
        "        if isinstance(vec, tf.Tensor):\n",
        "            vec = vec.numpy()\n",
        "        if isinstance(vec, np.ndarray):\n",
        "            # Use argmax since this will be used in the model created later\n",
        "            am = np.argmax(vec)\n",
        "        else:\n",
        "            am = vec\n",
        "        if am == 0:\n",
        "            return unknown_token\n",
        "        return self.index_to_char[am]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9nyVSBS_RnK"
      },
      "source": [
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Untersuchen Sie die gegebene Klasse zur One Hot Kodierung und die Funktion der einzelnen Methoden. \n",
        "\n",
        "(2) Erstellen Sie f√ºr das folgendes Alphabet `HWedlor` eine Instanz der Klasse `OneHot`. \n",
        "\n",
        "(3) Kodieren Sie nun die Zeichenfolge `Hello World!` mit der One Hot Kodierung. Wie wird das Zeichen `H` dargestellt? Geben Sie die Dimensionen des Vektors an.\n",
        "\n",
        "* Hinweis: Sie k√∂nnen zur Umwandlung des Strings in eine Liste von Zeichen die Funktion `tokenize` verwenden. Dies ist aber nicht zwingend erforderlich, da Python den String automatisch als Liste interpretieren kann."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXopuHLJadWN"
      },
      "source": [
        "> <Antwort hier einf√ºgen>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jCputAba8UN"
      },
      "source": [
        "(4) Wandeln Sie die kodierte Zeichenfolge zur√ºck in einen f√ºr Menschen lesbaren Text. Entspricht der zur√ºckgewandelte Text dem urspr√ºnglichen Input? Falls nicht, was k√∂nnte die Ursache daf√ºr sein?\n",
        "\n",
        "* Hinweis: F√ºr eine sch√∂nere Ausgabe kann der enkodierte Text mit der Funktion `untokenize` in einen String gewandelt werden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPiAwayxbi16"
      },
      "source": [
        "> <Antwort hier einf√ºgen>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjFH6Rbeab4P"
      },
      "source": [
        "def tokenize(text):\n",
        "    '''\n",
        "    Converts the given text (string) in a list of chars.\n",
        "    '''\n",
        "    return list(text)\n",
        "\n",
        "def untokenize(tokens):\n",
        "    '''\n",
        "    Converts the given tokens (list of chars) in a string.\n",
        "    '''\n",
        "    return \"\".join(tokens)\n",
        "\n",
        "tokens = 'HWedlor'\n",
        "\n",
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WglUJhhgyWSs"
      },
      "source": [
        "## 7.2 Datensatz vorbereiten\n",
        "\n",
        "In dieser √úbung verwenden wir einen Auszug aus dem frei zug√§nglichen Buch [Shakespeare](http://shakespeare.mit.edu/) als Datensatz. Ziel des Modells soll die Vorhersage weiterer Zeichen zu einer gegebenen Zeichensequenz sein.\n",
        "\n",
        "Sie k√∂nnen aus einem Buch (sehr lange Zeichensequenz) Trainingsdaten erzeugen, indem Sie jedem Zeichen das jeweils n√§chste Zeichen als Label zuweisen. Die folgende Grafik veranschaulicht dieses Verfahren:\n",
        "![Image](https://raw.githubusercontent.com/fhac-ewi/recurrent-neural-network/main/TrainData.png)\n",
        "\n",
        "In dieser Aufgabe wird das Buch einlegesen, mithilfe der One Hot Kodierung (Aufgabe 7.1) in Vektoren umgewandelt, in Teilsequenzen unterteilt und als Trainingsdaten und Validierungsdaten aufgeteilt.\n",
        "\n",
        "* Hinweis: Sie k√∂nnen theoretisch jeden beliebigen Text als Datensatz f√ºr das Training des Modells verwenden, wie z.B. die gesamten Harry Potter B√ºcher, Coronaschutzverordnungen oder auch Nachrichtenartikel.\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) F√ºhren Sie die folgende Codezelle aus, um das Buch Shakespeare einzulesen. Untersuchen Sie den Datensatz, indem Sie einen kurzen Auszug des Textes ausgeben.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79Qwlyaucvu0"
      },
      "source": [
        "# maximum text length \n",
        "# 1. Protection against \"OutOfMemory\" (poor RAM üò•)\n",
        "# 2. Adjustment for making training faster (but you will gain less accuracy)\n",
        "MAX_TEXT_LEN = 1_200_000 \n",
        "\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8') # .lower() f√ºr schnelleres Training anf√ºgen\n",
        "print(f'Length of text: {len(text)} characters')\n",
        "if len(text) > MAX_TEXT_LEN:\n",
        "    print(\"Text is too long. Cutting it to\", MAX_TEXT_LEN, f\"characters. That is {100 * MAX_TEXT_LEN / len(text):6.2f} %\")\n",
        "    text = text[:MAX_TEXT_LEN]\n",
        "\n",
        "# code here   \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD8tnErzN2YX"
      },
      "source": [
        "(2) Wandeln Sie den `text` in Tokens um (`tokenized_text`), indem Sie die Funktion `tokenize` anwenden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VZ6c1F1OZDl"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx1Wc-Z-c9m5"
      },
      "source": [
        "(3) Ermitteln Sie aus `tokenized_text` das Alphabet (`tokens`) und geben dessen L√§nge aus. Das Alphabet soll alle einzigartigen Zeichen des Textes enthalten.\n",
        "\n",
        "* Hinweis: Die Dokumentation von [Set](https://docs.python.org/3/tutorial/datastructures.html#sets) kann Ihnen bei dieser Aufgabe weiterhelfen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3CD1zKnc-Ar"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae-yuMS0c-aI"
      },
      "source": [
        "(4) Erstellen Sie f√ºr das Alphabet eine One Hot Kodierung und wenden diese auf den `tokenized_text` an. Nutzen Sie dazu Ihre Erkentnisse aus der Aufgabe 7.1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxh5yZSlc-1j"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufxc8wG5c_Tg"
      },
      "source": [
        "(5) Teilen Sie den kodierten Text (der ein gro√üer Datensatz ist) in Sequenzen (also in mehrere kleinere Datens√§tze) auf. Wie w√ºrden Sie die L√§nge der einzelnen Sequenzen w√§hlen? \n",
        "Verwenden Sie dazu die vorgegebene Funktion `sequenze_split`.\n",
        "\n",
        "* Hinweis: Die Sequenzen sollten lang genug sein, dass das RNN Zusammenh√§nge in einem Satz (und ggf. dar√ºber hinaus) erlernen kann. Die Sequenzl√§nge sollte jedoch kurz genug sein, damit eine ausreichende Anzahl an Datens√§tzen f√ºr das Training vorhanden ist.\n",
        "<br>Die von uns verwendete Sequenzl√§nge haben wir mit [Rot13](https://rot13.de/) kodiert: `Rvauhaqreg`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0vijKKDc_5b"
      },
      "source": [
        "# helper function for 7.2.5\n",
        "def sequenze_split(coded_text, sequence_len):\n",
        "    '''\n",
        "    Splits a given coded text (text converted with OneHot) into multiple sequences.\n",
        "\n",
        "    Parameters:\n",
        "    coded_text -- OneHot coded text (2D np.array) that will be splitted.\n",
        "    sequence_len -- Length of each sequence\n",
        "\n",
        "    Returns:\n",
        "    3D np.array with coded text splitted into sequences.\n",
        "    Shape will be (sequences, letters per sequence, letter as one hot coded vector)\n",
        "    '''\n",
        "    target_shape = (int(coded_text.shape[0] / (sequence_len + 1)) , (sequence_len + 1) , coded_text.shape[1])\n",
        "    coded_text_seq = np.empty(target_shape, dtype=coded_text.dtype)\n",
        "    for s in range(coded_text_seq.shape[0]):\n",
        "        coded_text_seq[s] = coded_text[s * (sequence_len + 1):(s + 1) * (sequence_len + 1)]\n",
        "  \n",
        "    return coded_text_seq  \n",
        "\n",
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0IfRdKdcwNL"
      },
      "source": [
        "(6) Erstellen Sie nun aus den sequenzierten Daten das Feature `X` und das Label `y`. F√ºr die Vorhersage von einzelnen Zeichen ist jeweils das n√§chste Zeichen das Label des vorherigen Zeichens. Das Label `y` wird deshalb aus den gleichen Werten des Features `X` gebildet, ist jedoch um +1 verschoben. \n",
        "\n",
        "\n",
        "* Beispiel: Die Sequenz `Hello World!` kann in **X** `Hello World` mit dem zugeh√∂rigen Label **y** `ello World!` aufgeteilt werden.\n",
        "* Hinweis: Untersuchen Sie die R√ºckgabe der Funktion `sequenze_split`. In welcher der drei Komponenten m√ºssen Sie die Verschiebung vornehmen?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpjJhmNMdMtQ"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA0UqltXdNK9"
      },
      "source": [
        "(7) Konvertieren Sie nun die Daten in ein Trainings- und Validierungsset. Nutzen Sie daf√ºr die Funktion `train_test_split` (Eine Dokumentation finden Sie [hier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN0KsVCb_Rm-"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDvkDpWsysjl"
      },
      "source": [
        "üéâüéâüéâ **Geschafft!** üéâüéâüéâ\n",
        "\n",
        "Sie haben nun aus einem Buch Trainingsdaten f√ºr ein RNN zur Vorhersage von Zeichen erstellt!\n",
        "Folgende Schritte haben Sie erfolgreich durchgef√ºhrt: \n",
        "- Text einlesen (und falls notwendig bereinigen)\n",
        "- Text in Tokens umwandeln\n",
        "- Alphabet festlegen\n",
        "- One Hot Kodierung erstellen und anwenden\n",
        "- In Sequenzen aufteilen\n",
        "- `X` und `y` festlegen\n",
        "- Aufteilung in Training und Validierungsset\n",
        "\n",
        "... jetzt k√∂nnen Sie mit dem eigentlichen Modell fortfahren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOMFCH7V_RnM"
      },
      "source": [
        "## 7.3 RNN Modell erstellen\n",
        "In dieser Aufgabe wird ein many-to-many [SimpleRNN](https://keras.io/api/layers/recurrent_layers/simple_rnn/) (auch als Vanilla bezeichnet) zur Vorhersage des weiteren Verlaufs einer Zeichensequenz erstellt.\n",
        "\n",
        "F√ºr die Erstellung eines Vanilla RNN werden Sie ein Sequential Model von Keras mit einer SimpleRNN Layer und einer Dense Layer nutzen. \n",
        "![Image](https://raw.githubusercontent.com/fhac-ewi/recurrent-neural-network/main/SimpleRNN.png)\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Bestimmen Sie nun die Parameter, die f√ºr das Modell ben√∂tigt werden:\n",
        "- Shape der Eingabe/des Trainingdatensatzes. (Anzahl Zeichen, L√§nge eines vektorisierten Zeichens)\n",
        "- L√§nge des Alphabets (inklusive des `unknown_tokens`). Also die Anzahl der Tokens, die das Modell vorhersagen k√∂nnen soll.\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JNXcbdvfoOF"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07w7qlrrfonH"
      },
      "source": [
        "\n",
        "(2) Erstellen Sie ein [Sequential](https://keras.io/api/models/sequential/) Modell und f√ºgen folgende Schichten hinzu:\n",
        "- [SimpleRNN](https://keras.io/api/layers/recurrent_layers/simple_rnn/) mit 128 RNN Units als Output Space (= Gr√∂√üe des Hidden State), der Shape der Eingabe und dem Parameter `return_sequences=true`. Wenn wir den Parameter `return_sequences=true` setzen, gibt unsere SimpleRNN-Schicht die gesamte Output-Sequenz zur√ºck (Das Resultat entspricht einem `many-to-many RNN`).\n",
        "- [Dense](https://keras.io/api/layers/core_layers/dense/) mit der Anzahl der Tokens und der Aktivierungsfunktion `softmax`.\n",
        "\n",
        "Kompilieren Sie anschlie√üend das Modell mit der Loss Function `categorical_crossentropy`, dem [RMSprop](https://keras.io/api/optimizers/rmsprop/) Optimizer mit einer `learning_rate` von 0.01 und f√ºgen als Metrics die `accuracy` hinzu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Uh7RmR_RnN"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axndj50eyWrw"
      },
      "source": [
        "## 7.4 RNN Modell trainieren\n",
        "In dieser Aufgabe soll das Modell trainiert werden sowie der Loss und die Accuracy untersucht werden.\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Wenden Sie die Methode [fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) auf Ihr Modell an. Geben Sie als Parameter neben den Trainingsdaten auch die Anzahl der Epochen, die Batchsize und die zuvor erstellten Validierungsdaten (Aufgabenteil 7.2.6) an. Speichern Sie das Ergebnis des Trainings f√ºr eine sp√§tere Analyse in einer Variable!\n",
        "\n",
        "Im Code sind bereits Startwerte f√ºr das Training vorgegeben. Sie k√∂nnen diese nach Belieben anpassen. \n",
        "\n",
        "**Eine Accuracy von 50% ist f√ºr diesen Schritt v√∂llig ausreichend!**\n",
        "\n",
        "* Hinweis: **Die Trainingsdauer sollte zwischen 1 und 3 Minuten liegen!** \n",
        "</br>Nach den ersten drei Epochen sollte die Genauigkeit bereits √ºber 30% liegen. Falls nicht, pr√ºfen Sie noch einmal die vorherigen Aufgabenteile oder bitten Sie das Team RNN um Hilfe!\n",
        "\n",
        "* Tipp: Falls Sie das Gef√ºhl haben, dass Ihr Modell noch einen Fehler enthalten k√∂nnte, f√ºgen Sie in Aufgabe 7.2 im Codeblock Zeile 8 ein `.lower()` ein. Dadurch wird der Datensatz in Kleinbuchstaben umgewandelt und die Gr√∂√üe des Alphabets verringert. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGpNzqcuyW5-"
      },
      "source": [
        "EPOCHS = 20\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "t1 = time.time()\n",
        "# code here\n",
        "\n",
        "\n",
        "\n",
        "t2 = time.time()\n",
        "\n",
        "print(\"Training took: \", timedelta(seconds=t2-t1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwFD7439_RnO"
      },
      "source": [
        "(2) Plotten Sie die Accuracy und den Loss des Trainingsets und des Validationsets √ºber die Epochen hinweg. Bewerten Sie den Verlauf des Trainings. Wie k√∂nnte das Training verbessert werden?\n",
        "* Hinweis: Die Accuracy und den Loss finden Sie in der [history](https://keras.io/api/models/model_training_apis/#fit-method) des Modells. Schauen Sie sich hierzu die R√ºckgabe der `fit-Methode` an."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCn3o8K9_RnO"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghcs0o_ABlKR"
      },
      "source": [
        "> <Antwort hier einf√ºgen>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxNyKthd_RnP"
      },
      "source": [
        "## 7.5 Vorhersagen treffen\n",
        "In diesem Schritt wollen wir unser zuvor trainiertes Modell f√ºr die Vorhersage von Buchstaben/Texten nutzen. Basierend auf den resultierenden S√§tzen k√∂nnen wir eine von der Accuracy unabh√§ngige Bewertung der Modellg√ºte erstellen.\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Vervollst√§ndigen Sie die Funktion `predict`. Kodieren Sie daf√ºr den Text mit der One Hot Kodierung, f√ºhren die Vorhersage mit dem trainierten Modell durch und geben das letzte dekodierte Zeichen der Vorhersage zur√ºck.  \n",
        "\n",
        "* Hinweis: Beachten Sie, dass die Methode `model.predict` immer Batches erwartet und der Input in eine andere Shape gebracht werden muss.\n",
        "\n",
        "Testen Sie anschlie√üend die Funktion mit einzelnen W√∂rtern. Geben Sie daf√ºr den ersten Teil des Wortes in die `predict` Funktion hinein und √ºberpr√ºfen die R√ºckgabe. Sie k√∂nnen auch k√ºrzere S√§tze hineingeben und die Ausgabe pr√ºfen.\n",
        "\n",
        "* Beispiel: Bei `Prince` wird der Input als `Princ` gew√§hlt und das erwartete Ergebnis lautet `e`.\n",
        "\n",
        "Wir haben Ihnen zus√§tzlich ein Widget mithilfe von [ipywidgets](https://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html#Using-Interact) programmiert, damit Sie verschiedene Inputs live testen k√∂nnen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3wVdygn_RnQ"
      },
      "source": [
        "def predict(text, one_hot, trainied_model):\n",
        "    '''\n",
        "    Wandelt den Text mithilfe der OneHot Kodierung in eine Input um, \n",
        "    f√ºhrt mithilfe des trainierten Modells eine prediction durch \n",
        "    und gibt das vorhergesagte Zeichen als Text aus.\n",
        "    '''\n",
        "    # coce here\n",
        "    \n",
        "\n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "print(\"Prediction of 'fathe' is:\", predict(\"fathe\", one_hot, model))   \n",
        "print(\"Prediction of 'Princ' is:\", predict(\"Princ\", one_hot, model))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSfFw9pEl6xt"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "def verbose_prediction(text, one_hot, trainied_model):\n",
        "    if len(text) == 0:\n",
        "        text = \" \"\n",
        "    prediction = predict(text=text, one_hot=one_hot, trainied_model=trainied_model)\n",
        "    print(f\"I think the next will be \\\"{prediction}\\\" after you said \\\"{text}\\\"\")\n",
        "\n",
        "w = widgets.interactive(verbose_prediction,\n",
        "                        text=widgets.Text(value='ROME', placeholder='Type something', description='Your text:', disabled=False),\n",
        "                        one_hot=widgets.fixed(one_hot),\n",
        "                        trainied_model=widgets.fixed(model),\n",
        "                       )\n",
        "\n",
        "verbose_prediction(\"Edwar\", one_hot=one_hot, trainied_model=model)\n",
        "\n",
        "display(w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGXTuk3VnLQb"
      },
      "source": [
        "(2) **Wettkampf** Erweitern Sie die Funktion `predict` aus dem vorherigen Aufgabenteil (7.5.1) zu einer Funktion, die 100 weitere Zeichen vorhersagt und somit wom√∂glich einen ganzen Satz vorhersagen kann. \n",
        "\n",
        "Reichen Sie Ihr bestes Ergebnis im [Discord Chat von Team RNN](https://discord.com/channels/829659610045481010/829659610210107434/846648596681195550) ein. Wenn Sie in den nachfolgenden Aufgaben bessere Ergebnisse erzielen, k√∂nnen Sie diese nat√ºrlich auch einreichen!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btPQKKCRn2xf"
      },
      "source": [
        "def predict_sentence(text, prediction_length, one_hot, trainied_model):\n",
        "    '''\n",
        "    F√ºhrt mehrere Predictions Iterativ durch.\n",
        "    '''\n",
        "    # code here\n",
        "    \n",
        "\n",
        "    \n",
        "    return text\n",
        "\n",
        "print(predict_sentence(\"ROMEO:\\n\", 100, one_hot, model))      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d7pKNy1ycN7"
      },
      "source": [
        "## 7.6 **Optional** RNN Varianten LSTM und GRU\n",
        "\n",
        "Neben SimpleRNN wurden in der Vorlesung zwei weitere Varianten von RNNs vorgestellt, die mit dem Vanishing Gradient Problem deutlich besser als das SimpleRNN umgehen k√∂nnen.\n",
        "\n",
        "In dieser Aufgabe sollen diese beiden Varianten trainiert und die Lernkurve sowie die getroffenen Vorhersagen mit dem SimpleRNN verglichen werden.\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Trainieren Sie auf dem gleichen Datensatz zwei Modelle der Varianten LSTM und GRU. Verwenden Sie Ihr Modell aus Aufgabe 7.3 und ersetzen Sie die SimpleRNN Layer durch eine passende [Layer von Keras](https://keras.io/api/layers/recurrent_layers/).\n",
        "\n",
        "**Speichern Sie die Modelle in neuen Variablen ab!**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IehQ7h3uyeY6"
      },
      "source": [
        "# code here\n",
        "# model_lstm = ....\n",
        "\n",
        "\n",
        "\n",
        "# model_gru = ....\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knXfKSKy_RnS"
      },
      "source": [
        "t1 = time.time()\n",
        "# code here (train lstm)\n",
        "\n",
        "\n",
        "\n",
        "t2 = time.time()\n",
        "t_lstm = t2 - t1\n",
        "\n",
        "t1 = time.time()\n",
        "# code here (train gru)\n",
        "\n",
        "\n",
        "\n",
        "t2 = time.time()\n",
        "t_gru = t2 - t1\n",
        "\n",
        "print(\"LSTM Training took:\", timedelta(seconds=t_lstm))\n",
        "print(\"GRU  Training took:\", timedelta(seconds=t_gru))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZyureKEhM0H"
      },
      "source": [
        "(2) Plotten Sie die Accuracy und den Loss der drei Modelle in einem Diagramm. Verwenden Sie zus√§tzlich die Methode `predict_sentence` (7.5.2), um die Vorhersagen zu vergleichen.\n",
        "Welche Erkenntnisse haben Sie aus dem Training gezogen? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8fe7kxBhFOM"
      },
      "source": [
        "> <Antwort hier einf√ºgen>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HlKt70B_RnT"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMWgGgRZ_RnT"
      },
      "source": [
        "## 7.7 **Optional** Schriftsteller\n",
        "\n",
        "Mit den Erkenntnissen aus der Vorlesung, den vorherigen √úbungsaufgaben und ein bisschen Python Erfahrung sind Sie nun in der Lage nicht nur einzele Buchstaben vorherzusagen, sondern k√∂nnten auch beliebig viele Zeichen generieren und dadurch ganze B√ºcher schreiben [lassen].\n",
        "\n",
        "Sie k√∂nnen f√ºr diese Aufgabe den urspr√ºnglichen Datensatz anpassen und beispielsweise die Coronaschutzverordnung, wissenschaftliche Artikel oder Meldungen aus Tageszeitungen verwenden.\n",
        "\n",
        "Gelingt es Ihnen den 8ten Band von Harry Potter zu erstellen?\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Was m√ºssten Sie √§ndern, um mithilfe des bisherigen Modells ein ganzes Buch erstellen zu lassen? Glauben Sie, dass das Ergebnis lesbar w√§re?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yduJYx0HiaMr"
      },
      "source": [
        "> <Antwort hier einf√ºgen>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wyhz--mz_RnT"
      },
      "source": [
        "(2) Erstellen Sie ein neues Modell, welches zu einem gegebenen Text von wenigen Worten in der Lage ist, ein ganzes Buch vorherzusagen. Ihnen sind keine Grenzen gesetzt. Sie sind jetzt frei! üß¶ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veFi0Rf1keez"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}