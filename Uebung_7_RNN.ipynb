{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Uebung-7-RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fhac-ewi/recurrent-neural-network/blob/main/Uebung_7_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYD6gvw1vwii"
      },
      "source": [
        "# Ãœbung 7 - Rekurrente neuronale Netze (RNNs)\n",
        "\n",
        "## In dieser Ãœbung ...\n",
        "... beschÃ¤ftigen wir uns mit rekurrenten neuronalen Netzen, die unter anderem fÃ¼r die Textvorhersage (`text prediction`) eingesetzt werden kÃ¶nnen. In dieser Ãœbung werden Sie  ein eigenes Modell zur Vorhersage weiterer Buchstaben (Zeichen) zu einer gegebenen Buchstabensequenz erstellen. \n",
        "\n",
        "Dazu werden Sie einen Datensatz fÃ¼r das Training vorbereiten, ein Standard-RNN mithilfe von Keras implementieren und fÃ¼r die Vorhersage des nÃ¤chsten Zeichens und sogar ganzen SÃ¤tzen nutzen.\n",
        "\n",
        "Wenn Sie diese ersten Schritte geschafft haben und noch Zeit haben, dÃ¼rfen Sie die beiden weiteren Varianten (LSTM und GRU) implementieren und anschlieÃŸend die Genauigkeit (Accuracy) der Netze miteinander vergleichen. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a_ZEFJfHuuF"
      },
      "source": [
        "## 7.0 Vorbereitung\n",
        "\n",
        "In diesem Abschnitt mÃ¼ssen Sie nichts programmieren! ðŸŽ‰\n",
        "\n",
        "Wir haben bereits alle notwendigen Imports fÃ¼r diese Ãœbung hinzugefÃ¼gt, sodass Sie direkt starten kÃ¶nnen. Sie mÃ¼ssen lediglich die GPU UnterstÃ¼tzung in Google Colab aktivieren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc_GxdsyIDYP"
      },
      "source": [
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Aktivieren Sie bitte die GPU UnterstÃ¼tzung in Google Colab. Wechseln Sie unter dem Reiter `Laufzeit` -> `Laufzeittyp Ã¤ndern` von `None` auf `GPU` und bestÃ¤tigen Sie diese Ã„nderung.\n",
        "\n",
        "(2) FÃ¼hren Sie die folgende Codezelle aus, um die erforderlichen Bibliotheken zu importieren und die GPU UnterstÃ¼tzung zu prÃ¼fen. \n",
        "\n",
        "  * Hinweis: Wenn Sie dieses Notebook mit dem Direktlink von GitHub geÃ¶ffnet haben, wird bei der erstmaligen AusfÃ¼hrung eine Warnung angezeigt. Diese mÃ¼ssen Sie durch den Klick auf `Trotzdem ausfÃ¼hren` bestÃ¤tigen. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-cFD9IFItkB"
      },
      "source": [
        "# Import everything needed for this exercise \n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime, timedelta\n",
        "from termcolor import colored\n",
        "import logging\n",
        "\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "print(f\"Keras Version: {keras.__version__}; Tensorflow version: {tf.__version__}; NumPy version: {np.__version__}; Python version: \", \".\".join(str(x) for x in sys.version_info[:3]))\n",
        "\n",
        "# Reset random number generators\n",
        "seed = 1337\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Check GPU support\n",
        "from tensorflow.python.client import device_lib\n",
        "physical_devices = device_lib.list_local_devices()\n",
        "print(\"You are using\", len(physical_devices), \"local devises.\", len([x for x in physical_devices if x.device_type == \"GPU\"]), \"are GPUs\")\n",
        "for i, d in enumerate(physical_devices):\n",
        "    print(\"  -> Device\", i+1, \"is a\", d.device_type, \"=>\", d.physical_device_desc if len(d.physical_device_desc) > 0 else d.name)\n",
        "\n",
        "if len([x for x in physical_devices if x.device_type == \"GPU\"]) == 0:\n",
        "  raise Exception(\"Please enable GPU support before using this notebook. See here: [Runtime] -> [Change runtime type]\")    \n",
        "\n",
        "print(\"\\nðŸŽ‰ðŸŽ‰ðŸŽ‰ You are ready to go! ðŸŽ‰ðŸŽ‰ðŸŽ‰\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1CXeYPHyywV"
      },
      "source": [
        "## 7.1 One Hot Kodierung\n",
        "\n",
        "Wir haben in der Vorlesung die One Hot Kodierung (1-aus-n-Code) kennen gelernt. Diese ermÃ¶glicht es Zeichen eines Alphabets als Vektoren darzustellen. \n",
        "\n",
        "FÃ¼r ein Alphabet mit `n` einzigartigen Zeichen wird ein Vektor der LÃ¤nge `n` benÃ¶tigt. Jedes einzigartige Zeichen wird hierbei als Einheitsvektor definiert. Eine Zeichensequenz mit `m` Zeichen wird als `m` Vektoren mit jeweils der LÃ¤nge `n` dargestellt.  \n",
        "\n",
        "**Hinweis** Die vorliegende Implementierung ist fÃ¼r den Umgang mit Zeichen auÃŸerhalb des Alphabets konzipiert. Deshalb wird zur Darstellung eines Alphabets mit `n` einzigartigen Zeichen ein Vektor der LÃ¤nge `n+1` erstellt. Alle Zeichen auÃŸerhalb des Alphabets werden durch das `unknown_token` ersetzt. \n",
        "\n",
        "FÃ¼r das Training unseres Netzes werden wir die One Hot Kodierung zur Umwandlung eines Textes in Trainingsdaten nutzen. (Aufgabe 7.2)\n",
        "\n",
        "* Hinweis: FÃ¼r weitere Informationen zur One Hot Kodierun schlagen Sie diese in der Vorlesung nach oder benutzen Sie das [Internet](https://www.semanticscholar.org/search?q=one%20hot%20coder&sort=relevance)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miApcJctvteM"
      },
      "source": [
        "class OneHot(object):\n",
        "    def __init__(self, tokens, unknown_token = \"[UNKNOWN]\"):\n",
        "        '''\n",
        "        Creates a new instance of this class. \n",
        "\n",
        "        OneHot can be used to translate categorical data into vectors.\n",
        "\n",
        "        Parameters\n",
        "        tokens -- The tokens you want to be able to encode and decode\n",
        "        unknown_token -- The token to be used when decoding and the net wants to use a not known char\n",
        "        '''\n",
        "        self.tokens = tokens\n",
        "        self.unknown_token = unknown_token\n",
        "        # Store a bidirectional dictionary containing the characters\n",
        "        self.char_to_index = dict((token, i + 1) for i, token in enumerate(self.tokens))\n",
        "        self.index_to_char = dict((i + 1, token) for i, token in enumerate(self.tokens))\n",
        "        pass\n",
        "\n",
        "    def encode(self, text_as_tokens, dtype=np.bool_):\n",
        "        '''\n",
        "        Encodes a tokenized text into a matrix (each token as vector).\n",
        "\n",
        "        Parameters:\n",
        "        text_as_tokens -- List of tokens\n",
        "        dtype -- (optional) data type like int or bool for optimized performance\n",
        "\n",
        "        Returns:\n",
        "        np.array of OneHot encoded tokens (matrix)\n",
        "        '''\n",
        "        # Create the encoding matrix\n",
        "        enc = np.empty((len(text_as_tokens), len(self.tokens) + 1), dtype=dtype)\n",
        "        for i, token in enumerate(text_as_tokens):\n",
        "            # Encode every char\n",
        "            enc[i] = self.encode_token(token=token, dtype=dtype)\n",
        "        return enc\n",
        "    \n",
        "    def encode_token(self, token, dtype=np.bool_):\n",
        "        '''\n",
        "        Encodes a single token into a vector.\n",
        "\n",
        "        Parameters:\n",
        "        token -- Single token\n",
        "        dtype -- (optional) data type like int or bool for optimized performance\n",
        "\n",
        "        Returns:\n",
        "        np.array of OneHot encoded token (vector)\n",
        "        '''\n",
        "        l = len(self.tokens) + 1\n",
        "        ret = np.zeros((1, l), dtype=dtype)\n",
        "        if token not in self.char_to_index:\n",
        "            ret[0, 0] = 1\n",
        "        else:\n",
        "            ret[0, self.char_to_index[token]] = 1\n",
        "        return ret\n",
        "    \n",
        "    def decode(self, mat, unknown_token=None):         \n",
        "        '''\n",
        "        Decodes a matrix into an array of tokens.\n",
        "\n",
        "        Parameters:\n",
        "        mat -- matrix to be decoded. Has to be of shape (len_of_text, vocab_size)\n",
        "        unknown_token -- Unknown token. If none uses the one from __init__\n",
        "\n",
        "        Returns:\n",
        "        array of tokens (chars)\n",
        "        '''\n",
        "        return [self.decode_token(mat[x]) for x in range(mat.shape[0])]\n",
        "    \n",
        "    def decode_token(self, vec, unknown_token=None):\n",
        "        '''\n",
        "        Decodes a vector into a token.\n",
        "\n",
        "        Parameters:\n",
        "        vec -- Vector that should be decoded. Has to be on vocab length\n",
        "        unknown_token -- Unknown token. If none uses the one from __init__\n",
        "\n",
        "        Returns:\n",
        "        single token (char)\n",
        "        '''\n",
        "        if unknown_token is None:\n",
        "            unknown_token = self.unknown_token\n",
        "        if isinstance(vec, tf.Tensor):\n",
        "            vec = vec.numpy()\n",
        "        if isinstance(vec, np.ndarray):\n",
        "            # Use argmax since this will be used in the model created later\n",
        "            am = np.argmax(vec)\n",
        "        else:\n",
        "            am = vec\n",
        "        if am == 0:\n",
        "            return unknown_token\n",
        "        return self.index_to_char[am]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9nyVSBS_RnK"
      },
      "source": [
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Untersuchen Sie die gegebene Klasse zur One Hot Kodierung und die Funktion der einzelnen Methoden. \n",
        "\n",
        "(2) Erstellen Sie fÃ¼r das folgendes Alphabet `HWedlor` eine Instanz der Klasse `OneHot`. \n",
        "\n",
        "(3) Kodieren Sie nun die Zeichenfolge `Hello World!` mit der One Hot Kodierung. Wie wird das Zeichen `H` dargestellt? Geben Sie die Dimensionen des Vektors an.\n",
        "\n",
        "* Hinweis: Sie kÃ¶nnen zur Umwandlung des Strings in eine Liste von Zeichen die Funktion `tokenize` verwenden. Dies ist aber nicht zwingend erforderlich, da Python den String automatisch als Liste interpretieren kann."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXopuHLJadWN"
      },
      "source": [
        "> <Antwort hier einfÃ¼gen>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jCputAba8UN"
      },
      "source": [
        "(4) Wandeln Sie die kodierte Zeichenfolge zurÃ¼ck in einen fÃ¼r Menschen lesbaren Text. Entspricht der zurÃ¼ckgewandelte Text dem ursprÃ¼nglichen Input? Falls nicht, was kÃ¶nnte die Ursache dafÃ¼r sein?\n",
        "\n",
        "* Hinweis: FÃ¼r eine schÃ¶nere Ausgabe kann der enkodierte Text mit der Funktion `untokenize` in einen String gewandelt werden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPiAwayxbi16"
      },
      "source": [
        "> <Antwort hier einfÃ¼gen>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjFH6Rbeab4P"
      },
      "source": [
        "def tokenize(text):\n",
        "    '''\n",
        "    Converts the given text (string) in a list of chars.\n",
        "    '''\n",
        "    return list(text)\n",
        "\n",
        "def untokenize(tokens):\n",
        "    '''\n",
        "    Converts the given tokens (list of chars) in a string.\n",
        "    '''\n",
        "    return \"\".join(tokens)\n",
        "\n",
        "tokens = 'HWedlor'\n",
        "\n",
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WglUJhhgyWSs"
      },
      "source": [
        "## 7.2 Datensatz vorbereiten\n",
        "\n",
        "In dieser Ãœbung verwenden wir einen Auszug aus dem frei zugÃ¤nglichen Buch [Shakespeare](http://shakespeare.mit.edu/) als Datensatz. Ziel des Modells soll die Vorhersage weiterer Zeichen zu einer gegebenen Zeichensequenz sein.\n",
        "\n",
        "Sie kÃ¶nnen aus einem Buch (sehr lange Zeichensequenz) Trainingsdaten erzeugen, indem Sie jedem Zeichen das jeweils nÃ¤chste Zeichen als Label zuweisen. Die folgende Grafik veranschaulicht dieses Verfahren:\n",
        "![Image](https://raw.githubusercontent.com/fhac-ewi/recurrent-neural-network/main/TrainData.png)\n",
        "\n",
        "In dieser Aufgabe wird das Buch einlegesen, mithilfe der One Hot Kodierung (Aufgabe 7.1) in Vektoren umgewandelt, in Teilsequenzen unterteilt und als Trainingsdaten und Validierungsdaten aufgeteilt.\n",
        "\n",
        "* Hinweis: Sie kÃ¶nnen theoretisch jeden beliebigen Text als Datensatz fÃ¼r das Training des Modells verwenden, wie z.B. die gesamten Harry Potter BÃ¼cher, Coronaschutzverordnungen oder auch Nachrichtenartikel.\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) FÃ¼hren Sie die folgende Codezelle aus, um das Buch Shakespeare einzulesen. Untersuchen Sie den Datensatz, indem Sie einen kurzen Auszug des Textes ausgeben.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79Qwlyaucvu0"
      },
      "source": [
        "# maximum text length \n",
        "# 1. Protection against \"OutOfMemory\" (poor RAM ðŸ˜¥)\n",
        "# 2. Adjustment for making training faster (but you will gain less accuracy)\n",
        "MAX_TEXT_LEN = 1_200_000 \n",
        "\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8') # .lower() fÃ¼r schnelleres Training anfÃ¼gen\n",
        "print(f'Length of text: {len(text)} characters')\n",
        "if len(text) > MAX_TEXT_LEN:\n",
        "    print(\"Text is too long. Cutting it to\", MAX_TEXT_LEN, f\"characters. That is {100 * MAX_TEXT_LEN / len(text):6.2f} %\")\n",
        "    text = text[:MAX_TEXT_LEN]\n",
        "\n",
        "# code here   \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD8tnErzN2YX"
      },
      "source": [
        "(2) Wandeln Sie den `text` in Tokens um (`tokenized_text`), indem Sie die Funktion `tokenize` anwenden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VZ6c1F1OZDl"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx1Wc-Z-c9m5"
      },
      "source": [
        "(3) Ermitteln Sie aus `tokenized_text` das Alphabet (`tokens`) und geben dessen LÃ¤nge aus. Das Alphabet soll alle einzigartigen Zeichen des Textes enthalten.\n",
        "\n",
        "* Hinweis: Die Dokumentation von [Set](https://docs.python.org/3/tutorial/datastructures.html#sets) kann Ihnen bei dieser Aufgabe weiterhelfen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3CD1zKnc-Ar"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae-yuMS0c-aI"
      },
      "source": [
        "(4) Erstellen Sie fÃ¼r das Alphabet eine One Hot Kodierung und wenden diese auf den `tokenized_text` an. Nutzen Sie dazu Ihre Erkentnisse aus der Aufgabe 7.1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxh5yZSlc-1j"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufxc8wG5c_Tg"
      },
      "source": [
        "(5) Teilen Sie den kodierten Text (der ein groÃŸer Datensatz ist) in Sequenzen (also in mehrere kleinere DatensÃ¤tze) auf. Wie wÃ¼rden Sie die LÃ¤nge der einzelnen Sequenzen wÃ¤hlen? \n",
        "Verwenden Sie dazu die vorgegebene Funktion `sequenze_split`.\n",
        "\n",
        "* Hinweis: Die Sequenzen sollten lang genug sein, dass das RNN ZusammenhÃ¤nge in einem Satz (und ggf. darÃ¼ber hinaus) erlernen kann. Die SequenzlÃ¤nge sollte jedoch kurz genug sein, damit eine ausreichende Anzahl an DatensÃ¤tzen fÃ¼r das Training vorhanden ist.\n",
        "<br>Die von uns verwendete SequenzlÃ¤nge haben wir mit [Rot13](https://rot13.de/) kodiert: `Rvauhaqreg`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0vijKKDc_5b"
      },
      "source": [
        "# helper function for 7.2.5\n",
        "def sequenze_split(coded_text, sequence_len):\n",
        "    '''\n",
        "    Splits a given coded text (text converted with OneHot) into multiple sequences.\n",
        "\n",
        "    Parameters:\n",
        "    coded_text -- OneHot coded text (2D np.array) that will be splitted.\n",
        "    sequence_len -- Length of each sequence\n",
        "\n",
        "    Returns:\n",
        "    3D np.array with coded text splitted into sequences.\n",
        "    Shape will be (sequences, letters per sequence, letter as one hot coded vector)\n",
        "    '''\n",
        "    target_shape = (int(coded_text.shape[0] / (sequence_len + 1)) , (sequence_len + 1) , coded_text.shape[1])\n",
        "    coded_text_seq = np.empty(target_shape, dtype=coded_text.dtype)\n",
        "    for s in range(coded_text_seq.shape[0]):\n",
        "        coded_text_seq[s] = coded_text[s * (sequence_len + 1):(s + 1) * (sequence_len + 1)]\n",
        "  \n",
        "    return coded_text_seq  \n",
        "\n",
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0IfRdKdcwNL"
      },
      "source": [
        "(6) Erstellen Sie nun aus den sequenzierten Daten das Feature `X` und das Label `y`. FÃ¼r die Vorhersage von einzelnen Zeichen ist jeweils das nÃ¤chste Zeichen das Label des vorherigen Zeichens. Das Label `y` wird deshalb aus den gleichen Werten des Features `X` gebildet, ist jedoch um +1 verschoben. \n",
        "\n",
        "\n",
        "* Beispiel: Die Sequenz `Hello World!` kann in **X** `Hello World` mit dem zugehÃ¶rigen Label **y** `ello World!` aufgeteilt werden.\n",
        "* Hinweis: Untersuchen Sie die RÃ¼ckgabe der Funktion `sequenze_split`. In welcher der drei Komponenten mÃ¼ssen Sie die Verschiebung vornehmen?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpjJhmNMdMtQ"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA0UqltXdNK9"
      },
      "source": [
        "(7) Konvertieren Sie nun die Daten in ein Trainings- und Validierungsset. Nutzen Sie dafÃ¼r die Funktion `train_test_split` (Eine Dokumentation finden Sie [hier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN0KsVCb_Rm-"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDvkDpWsysjl"
      },
      "source": [
        "ðŸŽ‰ðŸŽ‰ðŸŽ‰ **Geschafft!** ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
        "\n",
        "Sie haben nun aus einem Buch Trainingsdaten fÃ¼r ein RNN zur Vorhersage von Zeichen erstellt!\n",
        "Folgende Schritte haben Sie erfolgreich durchgefÃ¼hrt: \n",
        "- Text einlesen (und falls notwendig bereinigen)\n",
        "- Text in Tokens umwandeln\n",
        "- Alphabet festlegen\n",
        "- One Hot Kodierung erstellen und anwenden\n",
        "- In Sequenzen aufteilen\n",
        "- `X` und `y` festlegen\n",
        "- Aufteilung in Training und Validierungsset\n",
        "\n",
        "... jetzt kÃ¶nnen Sie mit dem eigentlichen Modell fortfahren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOMFCH7V_RnM"
      },
      "source": [
        "## 7.3 RNN Modell erstellen\n",
        "In dieser Aufgabe wird ein many-to-many [SimpleRNN](https://keras.io/api/layers/recurrent_layers/simple_rnn/) (auch als Vanilla bezeichnet) zur Vorhersage des weiteren Verlaufs einer Zeichensequenz erstellt.\n",
        "\n",
        "FÃ¼r die Erstellung eines Vanilla RNN werden Sie ein Sequential Model von Keras mit einer SimpleRNN Layer und einer Dense Layer nutzen. \n",
        "![Image](https://raw.githubusercontent.com/fhac-ewi/recurrent-neural-network/main/SimpleRNN.png)\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Bestimmen Sie nun die Parameter, die fÃ¼r das Modell benÃ¶tigt werden:\n",
        "- Shape der Eingabe/des Trainingdatensatzes. (Anzahl Zeichen, LÃ¤nge eines vektorisierten Zeichens)\n",
        "- LÃ¤nge des Alphabets (inklusive des `unknown_tokens`). Also die Anzahl der Tokens, die das Modell vorhersagen kÃ¶nnen soll.\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JNXcbdvfoOF"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07w7qlrrfonH"
      },
      "source": [
        "\n",
        "(2) Erstellen Sie ein [Sequential](https://keras.io/api/models/sequential/) Modell und fÃ¼gen folgende Schichten hinzu:\n",
        "- [SimpleRNN](https://keras.io/api/layers/recurrent_layers/simple_rnn/) mit 128 RNN Units als Output Space (= GrÃ¶ÃŸe des Hidden State), der Shape der Eingabe und dem Parameter `return_sequences=true`. Wenn wir den Parameter `return_sequences=true` setzen, gibt unsere SimpleRNN-Schicht die gesamte Output-Sequenz zurÃ¼ck (Das Resultat entspricht einem `many-to-many RNN`).\n",
        "- [Dense](https://keras.io/api/layers/core_layers/dense/) mit der Anzahl der Tokens und der Aktivierungsfunktion `softmax`.\n",
        "\n",
        "Kompilieren Sie anschlieÃŸend das Modell mit der Loss Function `categorical_crossentropy`, dem [RMSprop](https://keras.io/api/optimizers/rmsprop/) Optimizer mit einer `learning_rate` von 0.01 und fÃ¼gen als Metrics die `accuracy` hinzu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Uh7RmR_RnN"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axndj50eyWrw"
      },
      "source": [
        "## 7.4 RNN Modell trainieren\n",
        "In dieser Aufgabe soll das Modell trainiert werden sowie der Loss und die Accuracy untersucht werden.\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Wenden Sie die Methode [fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) auf Ihr Modell an. Geben Sie als Parameter neben den Trainingsdaten auch die Anzahl der Epochen, die Batchsize und die zuvor erstellten Validierungsdaten (Aufgabenteil 7.2.6) an. Speichern Sie das Ergebnis des Trainings fÃ¼r eine spÃ¤tere Analyse in einer Variable!\n",
        "\n",
        "Im Code sind bereits Startwerte fÃ¼r das Training vorgegeben. Sie kÃ¶nnen diese nach Belieben anpassen. \n",
        "\n",
        "**Eine Accuracy von 50% ist fÃ¼r diesen Schritt vÃ¶llig ausreichend!**\n",
        "\n",
        "* Hinweis: **Die Trainingsdauer sollte zwischen 1 und 3 Minuten liegen!** \n",
        "</br>Nach den ersten drei Epochen sollte die Genauigkeit bereits Ã¼ber 30% liegen. Falls nicht, prÃ¼fen Sie noch einmal die vorherigen Aufgabenteile oder bitten Sie das Team RNN um Hilfe!\n",
        "\n",
        "* Tipp: Falls Sie das GefÃ¼hl haben, dass Ihr Modell noch einen Fehler enthalten kÃ¶nnte, fÃ¼gen Sie in Aufgabe 7.2 im Codeblock Zeile 8 ein `.lower()` ein. Dadurch wird der Datensatz in Kleinbuchstaben umgewandelt und die GrÃ¶ÃŸe des Alphabets verringert. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGpNzqcuyW5-"
      },
      "source": [
        "EPOCHS = 20\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "t1 = time.time()\n",
        "# code here\n",
        "\n",
        "\n",
        "\n",
        "t2 = time.time()\n",
        "\n",
        "print(\"Training took: \", timedelta(seconds=t2-t1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwFD7439_RnO"
      },
      "source": [
        "(2) Plotten Sie die Accuracy und den Loss des Trainingsets und des Validationsets Ã¼ber die Epochen hinweg. Bewerten Sie den Verlauf des Trainings. Wie kÃ¶nnte das Training verbessert werden?\n",
        "* Hinweis: Die Accuracy und den Loss finden Sie in der [history](https://keras.io/api/models/model_training_apis/#fit-method) des Modells. Schauen Sie sich hierzu die RÃ¼ckgabe der `fit-Methode` an."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCn3o8K9_RnO"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghcs0o_ABlKR"
      },
      "source": [
        "> <Antwort hier einfÃ¼gen>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxNyKthd_RnP"
      },
      "source": [
        "## 7.5 Vorhersagen treffen\n",
        "In diesem Schritt wollen wir unser zuvor trainiertes Modell fÃ¼r die Vorhersage von Buchstaben/Texten nutzen. Basierend auf den resultierenden SÃ¤tzen kÃ¶nnen wir eine von der Accuracy unabhÃ¤ngige Bewertung der ModellgÃ¼te erstellen.\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) VervollstÃ¤ndigen Sie die Funktion `predict`. Kodieren Sie dafÃ¼r den Text mit der One Hot Kodierung, fÃ¼hren die Vorhersage mit dem trainierten Modell durch und geben das letzte dekodierte Zeichen der Vorhersage zurÃ¼ck.  \n",
        "\n",
        "* Hinweis: Beachten Sie, dass die Methode `model.predict` immer Batches erwartet und der Input in eine andere Shape gebracht werden muss.\n",
        "\n",
        "Testen Sie anschlieÃŸend die Funktion mit einzelnen WÃ¶rtern. Geben Sie dafÃ¼r den ersten Teil des Wortes in die `predict` Funktion hinein und Ã¼berprÃ¼fen die RÃ¼ckgabe. Sie kÃ¶nnen auch kÃ¼rzere SÃ¤tze hineingeben und die Ausgabe prÃ¼fen.\n",
        "\n",
        "* Beispiel: Bei `Prince` wird der Input als `Princ` gewÃ¤hlt und das erwartete Ergebnis lautet `e`.\n",
        "\n",
        "Wir haben Ihnen zusÃ¤tzlich ein Widget mithilfe von [ipywidgets](https://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html#Using-Interact) programmiert, damit Sie verschiedene Inputs live testen kÃ¶nnen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3wVdygn_RnQ"
      },
      "source": [
        "def predict(text, one_hot, trainied_model):\n",
        "    '''\n",
        "    Wandelt den Text mithilfe der OneHot Kodierung in eine Input um, \n",
        "    fÃ¼hrt mithilfe des trainierten Modells eine prediction durch \n",
        "    und gibt das vorhergesagte Zeichen als Text aus.\n",
        "    '''\n",
        "    # coce here\n",
        "    \n",
        "\n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "print(\"Prediction of 'fathe' is:\", predict(\"fathe\", one_hot, model))   \n",
        "print(\"Prediction of 'Princ' is:\", predict(\"Princ\", one_hot, model))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSfFw9pEl6xt"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "def verbose_prediction(text, one_hot, trainied_model):\n",
        "    if len(text) == 0:\n",
        "        text = \" \"\n",
        "    prediction = predict(text=text, one_hot=one_hot, trainied_model=trainied_model)\n",
        "    print(f\"I think the next will be \\\"{prediction}\\\" after you said \\\"{text}\\\"\")\n",
        "\n",
        "w = widgets.interactive(verbose_prediction,\n",
        "                        text=widgets.Text(value='ROME', placeholder='Type something', description='Your text:', disabled=False),\n",
        "                        one_hot=widgets.fixed(one_hot),\n",
        "                        trainied_model=widgets.fixed(model),\n",
        "                       )\n",
        "\n",
        "verbose_prediction(\"Edwar\", one_hot=one_hot, trainied_model=model)\n",
        "\n",
        "display(w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGXTuk3VnLQb"
      },
      "source": [
        "(2) **Wettkampf** Erweitern Sie die Funktion `predict` aus dem vorherigen Aufgabenteil (7.5.1) zu einer Funktion, die 100 weitere Zeichen vorhersagt und somit womÃ¶glich einen ganzen Satz vorhersagen kann. \n",
        "\n",
        "Reichen Sie Ihr bestes Ergebnis im [Discord Chat von Team RNN](https://discord.com/channels/829659610045481010/829659610210107434/846648596681195550) ein. Wenn Sie in den nachfolgenden Aufgaben bessere Ergebnisse erzielen, kÃ¶nnen Sie diese natÃ¼rlich auch einreichen!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btPQKKCRn2xf"
      },
      "source": [
        "def predict_sentence(text, prediction_length, one_hot, trainied_model):\n",
        "    '''\n",
        "    FÃ¼hrt mehrere Predictions Iterativ durch.\n",
        "    '''\n",
        "    # code here\n",
        "    \n",
        "\n",
        "    \n",
        "    return text\n",
        "\n",
        "print(predict_sentence(\"ROMEO:\\n\", 100, one_hot, model))      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d7pKNy1ycN7"
      },
      "source": [
        "## 7.6 **Optional** RNN Varianten LSTM und GRU\n",
        "\n",
        "Neben SimpleRNN wurden in der Vorlesung zwei weitere Varianten von RNNs vorgestellt, die mit dem Vanishing Gradient Problem deutlich besser als das SimpleRNN umgehen kÃ¶nnen.\n",
        "\n",
        "In dieser Aufgabe sollen diese beiden Varianten trainiert und die Lernkurve sowie die getroffenen Vorhersagen mit dem SimpleRNN verglichen werden.\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Trainieren Sie auf dem gleichen Datensatz zwei Modelle der Varianten LSTM und GRU. Verwenden Sie Ihr Modell aus Aufgabe 7.3 und ersetzen Sie die SimpleRNN Layer durch eine passende [Layer von Keras](https://keras.io/api/layers/recurrent_layers/).\n",
        "\n",
        "**Speichern Sie die Modelle in neuen Variablen ab!**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IehQ7h3uyeY6"
      },
      "source": [
        "# code here\n",
        "# model_lstm = ....\n",
        "\n",
        "\n",
        "\n",
        "# model_gru = ....\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knXfKSKy_RnS"
      },
      "source": [
        "t1 = time.time()\n",
        "# code here (train lstm)\n",
        "\n",
        "\n",
        "\n",
        "t2 = time.time()\n",
        "t_lstm = t2 - t1\n",
        "\n",
        "t1 = time.time()\n",
        "# code here (train gru)\n",
        "\n",
        "\n",
        "\n",
        "t2 = time.time()\n",
        "t_gru = t2 - t1\n",
        "\n",
        "print(\"LSTM Training took:\", timedelta(seconds=t_lstm))\n",
        "print(\"GRU  Training took:\", timedelta(seconds=t_gru))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZyureKEhM0H"
      },
      "source": [
        "(2) Plotten Sie die Accuracy und den Loss der drei Modelle in einem Diagramm. Verwenden Sie zusÃ¤tzlich die Methode `predict_sentence` (7.5.2), um die Vorhersagen zu vergleichen.\n",
        "Welche Erkenntnisse haben Sie aus dem Training gezogen? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8fe7kxBhFOM"
      },
      "source": [
        "> <Antwort hier einfÃ¼gen>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HlKt70B_RnT"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMWgGgRZ_RnT"
      },
      "source": [
        "## 7.7 **Optional** Schriftsteller\n",
        "\n",
        "Mit den Erkenntnissen aus der Vorlesung, den vorherigen Ãœbungsaufgaben und ein bisschen Python Erfahrung sind Sie nun in der Lage nicht nur einzele Buchstaben vorherzusagen, sondern kÃ¶nnten auch beliebig viele Zeichen generieren und dadurch ganze BÃ¼cher schreiben [lassen].\n",
        "\n",
        "Sie kÃ¶nnen fÃ¼r diese Aufgabe den ursprÃ¼nglichen Datensatz anpassen und beispielsweise die Coronaschutzverordnung, wissenschaftliche Artikel oder Meldungen aus Tageszeitungen verwenden.\n",
        "\n",
        "Gelingt es Ihnen den 8ten Band von Harry Potter zu erstellen?\n",
        "\n",
        "**Ihre Aufgaben**\n",
        "\n",
        "(1) Was mÃ¼ssten Sie Ã¤ndern, um mithilfe des bisherigen Modells ein ganzes Buch erstellen zu lassen? Glauben Sie, dass das Ergebnis lesbar wÃ¤re?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yduJYx0HiaMr"
      },
      "source": [
        "> <Antwort hier einfÃ¼gen>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wyhz--mz_RnT"
      },
      "source": [
        "(2) Erstellen Sie ein neues Modell, welches zu einem gegebenen Text von wenigen Worten in der Lage ist, ein ganzes Buch vorherzusagen. Ihnen sind keine Grenzen gesetzt. Sie sind jetzt frei! ðŸ§¦ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veFi0Rf1keez"
      },
      "source": [
        "# code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}